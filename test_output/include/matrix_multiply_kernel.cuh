// Generated by RoboDSL - DO NOT EDIT

#ifndef MATRIX_MULTIPLY_KERNEL_HPP
#define MATRIX_MULTIPLY_KERNEL_HPP

#include <cuda_runtime.h>
#include <cstdint>
#include <vector>
#include <memory>

// Forward declarations for CUDA types
struct cudaStream_t;

namespace robodsl {

/**
 * @brief CUDA kernel wrapper class for matrix_multiply
 * 
 * This class provides a C++ interface to CUDA kernels, handling memory management
 * and kernel launches. It's designed to work with the ROS2 node lifecycle.
 */
class matrix_multiplyKernel {
public:
    /**
     * @brief Construct a new matrix_multiply Kernel object
     * 
     * @param stream CUDA stream to use for kernel execution (nullptr for default stream)
     */
    explicit matrix_multiplyKernel(cudaStream_t* stream = nullptr);
    
    /**
     * @brief Destroy the matrix_multiply Kernel object
     * 
     * Frees all allocated device memory.
     */
    ~matrix_multiplyKernel();
    
    // Delete copy constructor and assignment operator
    matrix_multiplyKernel(const matrix_multiplyKernel&) = delete;
    matrix_multiplyKernel& operator=(const matrix_multiplyKernel&) = delete;
    
    /**
     * @brief Initialize the kernel with input data
     * 
     * @param input Input data to process
     * @return true if initialization was successful, false otherwise
     */
    bool initialize(const std::vector<float*>& input);
    
    /**
     * @brief Process the input data using the CUDA kernel
     * 
     * @param parameters Kernel parameters
     * @return std::vector<float*> Processed output data
     */
    std::vector<float*> process(const KernelParameters& parameters);
    
    /**
     * @brief Get the last error message, if any
     * 
     * @return std::string The last error message, or an empty string if no error
     */
    std::string getLastError() const { return last_error_; }
    
    /**
     * @brief Check if the kernel was initialized successfully
     * 
     * @return true if initialized, false otherwise
     */
    bool isInitialized() const { return initialized_; }
    
private:
    // Device memory pointers
    float** d_A_{nullptr};  //!< Device memory for A
    float** d_B_{nullptr};  //!< Device memory for B
    float** d_C_{nullptr};  //!< Device memory for C
    
    cudaStream_t* stream_{nullptr};  //!< CUDA stream for async operations
    bool initialized_{false};        //!< Whether the kernel is properly initialized
    std::string last_error_;         //!< Last error message, if any
    
    // CUDA kernel launch configuration
    static constexpr int kBlockSize = 16;  //!< Threads per block
    
    /**
     * @brief Check for CUDA errors and update last_error_ if needed
     * 
     * @param status CUDA status to check
     * @param context Context string for error messages
     * @return true if no error, false otherwise
     */
    bool checkCudaError(cudaError_t status, const std::string& context);
    
    /**
     * @brief Allocate device memory
     * 
     * @return true if allocation was successful, false otherwise
     */
    bool allocateDeviceMemory();
    
    /**
     * @brief Free device memory
     */
    void freeDeviceMemory();
};

} // namespace robodsl


#endif // MATRIX_MULTIPLY_KERNEL_HPP
