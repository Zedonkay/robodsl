// Comprehensive RoboDSL Example - Showcasing All Features
// This file demonstrates all the different possibilities available in RoboDSL

// ============================================================================
// GLOBAL INCLUDES
// ============================================================================
include <rclcpp/rclcpp.hpp>
include <std_msgs/msg/string.hpp>
include <sensor_msgs/msg/image.hpp>
include <geometry_msgs/msg/pose_stamped.hpp>
include <nav2_msgs/action/navigate_to_pose.hpp>
include <example_interfaces/srv/add_two_ints.hpp>
include <cv_bridge/cv_bridge.h>
include <opencv2/opencv.hpp>
include <cuda_runtime.h>
include <device_launch_parameters.h>

// ============================================================================
// CUSTOM MESSAGE DEFINITIONS
// ============================================================================
message CustomImage {
    uint32 width;
    uint32 height;
    uint8 data[];
    string format = "RGB";
    float64 timestamp;
}

message DetectionResult {
    uint32 id;
    string label;
    float64 confidence;
    float64 bbox_x;
    float64 bbox_y;
    float64 bbox_width;
    float64 bbox_height;
}

// ============================================================================
// CUSTOM SERVICE DEFINITIONS
// ============================================================================
service ImageProcessing {
    uint32 image_id;
    string operation;
    float64 threshold = 0.5;
    ---
    bool success;
    string error_message;
    uint32 processed_id;
}

// ============================================================================
// CUSTOM ACTION DEFINITIONS
// ============================================================================
action NavigationAction {
    float64 target_x;
    float64 target_y;
    float64 target_z;
    float64 target_yaw;
    ---
    float64 current_x;
    float64 current_y;
    float64 current_z;
    float64 current_yaw;
    float64 distance_to_goal;
    ---
    bool reached_goal;
    float64 final_distance;
    string status_message;
}

// ============================================================================
// ADVANCED C++ FEATURES
// ============================================================================

// Template struct for generic data containers
template<typename T> struct Vector {
    T* data;
    size_t size;
    size_t capacity;
}

// Template class with inheritance
template<typename T> class Matrix : public Vector<T> {
    size_t rows;
    size_t cols;
}

// Template function (commented out due to parser limitations)
// template<typename T> T sqr(x: T) {
//     return x * x;
// }

// Template alias
template<typename T> using Vec = std::vector<T>;

// Static assertions
static_assert(sizeof(int) == 4, "int must be 4 bytes");
static_assert(sizeof(float) == 4, "float must be 4 bytes");

// Global constexpr variables
global PI: constexpr float = 3.14159;
global MAX_SIZE: constexpr int = 1000;
global CUDA_BLOCK_SIZE: constexpr int = 256;

// Global device constants for CUDA
global CUDA_CONSTANTS: constexpr float = 1.0;

// Operator overloads (commented out due to parser limitations)
// def operator+(a: Vector<int>&, b: Vector<int>&) -> Vector<int> {
//     // Implementation for vector addition
// }

// def operator<<(stream: std::ostream&, vec: Vector<int>&) -> std::ostream& {
//     stream << "Vector[" << vec.size << "]";
//     return stream;
// }

// Constructor and destructor (commented out due to parser limitations)
// def Vector<T>::Vector(initial_size: size_t) {
//     data = new T[initial_size];
//     size = 0;
//     capacity = initial_size;
// }

// def Vector<T>::~Vector() {
//     delete[] data;
// }

// Bitfield struct (commented out due to parser limitations)
// struct Flags {
//     uint32_t enabled : 1;
//     uint32_t mode : 3;
//     uint32_t priority : 4;
//     uint32_t reserved : 24;
// }

// Function with attributes (commented out due to parser limitations)
// @device @forceinline
// fast_math(x: float) -> float {
//     return x * x;
// }

// C++ Concepts (commented out due to parser limitations)
// concept Arithmetic: requires T: T operator+(T, T) T operator*(T, T)

// Friend declaration (commented out due to parser limitations)
// friend class Matrix<T>;

// User-defined literal (commented out due to parser limitations)
// def operator""_deg(value: long double) -> float {
//     return value * M_PI / 180.0;
// }

// ============================================================================
// DYNAMIC RUNTIME CONFIGURATION
// ============================================================================
dynamic_parameters {
    parameter float64 max_speed = 2.0 {
        min_value: 0.1
        max_value: 10.0
        step: 0.1
        description: "Maximum robot speed in m/s"
    }
    parameter bool enable_safety = true {
        description: "Enable safety features"
    }
    parameter int max_iterations = 100 {
        min_value: 10
        max_value: 1000
        description: "Maximum iterations for algorithms"
    }
    parameter string algorithm = "fast" {
        description: "Algorithm to use for processing"
    }
}

dynamic_remaps {
    remap /camera/image_raw: /sim/camera/image_raw when: "simulation_mode"
    remap /cmd_vel: /hardware/cmd_vel when: "hardware_mode"
    remap /tf: /tf_static when: "static_tf_mode"
}

// ============================================================================
// SIMULATION CONFIGURATION
// ============================================================================
simulation gazebo {
    world {
        world_file: "empty.world"
        physics_engine: "ode"
        gravity: (0, 0, -9.81)
        max_step_size: 0.001
        real_time_factor: 1.0
    }
    
    robot robot1 {
        model_file: "robot.urdf"
        namespace: "robot1"
        initial_pose: (0, 0, 0, 0, 0, 0)
        plugins {
            plugin gazebo_ros_control {
                robot_param: "robot_description"
                robot_param_node: "robot_state_publisher"
            }
            plugin gazebo_ros_camera {
                camera_name: "camera"
                frame_name: "camera_link"
            }
        }
    }
    
    robot robot2 {
        model_file: "robot2.urdf"
        namespace: "robot2"
        initial_pose: (1, 0, 0, 0, 0, 0)
    }
    
    gui: true
    headless: false
}

// ============================================================================
// HARDWARE-IN-THE-LOOP CONFIGURATION
// ============================================================================
hardware_in_loop {
    simulation_nodes: perception_node, planning_node, navigation_node
    hardware_nodes: motor_controller, sensor_driver, safety_monitor
    bridge_config: "hil_bridge.yaml"
}

// ============================================================================
// CUDA KERNELS SECTION
// ============================================================================
cuda_kernels {
    // Vector addition kernel
    kernel vector_add {
        input: float* a, float* b, int size
        output: float* c
        
        block_size: (256, 1, 1)
        grid_size: (1, 1, 1)
        shared_memory: 1024
        use_thrust: true
        
        include <cuda_runtime.h>
        include <device_launch_parameters.h>
        include <thrust/device_vector.h>
        
        code {
            __global__ void vector_add_kernel(const float* a, const float* b, float* c, int size) {
                int i = blockIdx.x * blockDim.x + threadIdx.x;
                if (i < size) {
                    c[i] = a[i] + b[i];
                }
            }
        }
    }
    
    // Matrix multiplication kernel
    kernel matrix_multiply {
        input: float* a, float* b, int m, int n, int k
        output: float* c
        
        block_size: (16, 16, 1)
        grid_size: (1, 1, 1)
        shared_memory: 2048
        use_thrust: false
        
        code {
            __global__ void matrix_multiply_kernel(const float* a, const float* b, float* c, int m, int n, int k) {
                int idx = blockIdx.x * blockDim.x + threadIdx.x;
                if (idx < m * n) {
                    c[idx] = a[idx] * b[idx];
                }
            }
        }
    }
    
    // Image processing kernel with advanced CUDA features
    kernel image_filter {
        input: uchar* input_image, int width, int height
        output: uchar* output_image
        
        block_size: (32, 32, 1)
        grid_size: (1, 1, 1)
        shared_memory: 4096
        use_thrust: false
        
        // Advanced CUDA features
        use_streams: true
        stream_count: 4
        synchronize: false
        dynamic_parallelism: true
        multi_gpu: false
        gpu_count: 1
        gpu_memory_per_device: 1073741824
        gpu_architectures: ["sm_70", "sm_75", "sm_80"]
        compute_capabilities: [7.0, 7.5, 8.0]
        error_handling: "graceful"
        performance_monitoring: true
        memory_hierarchy: true
        concurrent_kernel: true
        advanced_synchronization: true
        mixed_precision: true
        memory_pool: true
        context_management: true
        driver_api: false
        runtime_api: true
        
        code {
            __global__ void image_filter_kernel(const uchar* input, uchar* output, int width, int height) {
                int idx = blockIdx.x * blockDim.x + threadIdx.x;
                if (idx < width * height) {
                    output[idx] = input[idx];
                }
            }
        }
    }
}

// ============================================================================
// ONNX MODELS SECTION
// ============================================================================
onnx_model classification_model {
    input: "input" -> "float32[1,3,224,224]"
    output: "output" -> "float32[1,1000]"
    device: cuda
    optimization: tensorrt
    precision: fp16
    per_tensor_quantization: false
    max_workspace_size: 1073741824
    max_batch_size: 1
    optimization_level: 3
}

onnx_model detection_model {
    input: "input" -> "float32[1,3,640,640]"
    output: "output" -> "float32[1,84,8400]"
    device: cuda
    optimization: tensorrt
    precision: fp16
    per_tensor_quantization: false
    max_workspace_size: 2147483648
    max_batch_size: 1
    optimization_level: 3
}

onnx_model segmentation_model {
    input: "input" -> "float32[1,3,512,512]"
    output: "output" -> "float32[1,21,512,512]"
    device: cuda
    optimization: tensorrt
    precision: fp16
    per_tensor_quantization: false
    max_workspace_size: 1073741824
    max_batch_size: 1
    optimization_level: 3
    performance_tuning: true
    memory_optimization: true
    multi_stream: true
    performance_monitoring: true
    compatibility_mode: false
    memory_management: true
    serialization: true
    parallel_execution: true
    error_recovery: true
    parallel_streams: 4
    error_handling: "graceful"
    memory_pool_size: 268435456
    monitoring_metrics: ["latency", "throughput", "memory_usage"]
    backward_compatibility: true
    plugin_paths: ["/usr/local/cuda/plugins"]
    tuning_algorithm: "auto"
    engine_file: "segmentation_model.trt"
    profiling: true
    debugging: false
    custom_plugins: ["custom_segmentation_plugin"]
    tuning_iterations: 1000
    memory_pool_growth: "exponential"
    stream_count: 4
    stream_priority: "high"
    stream_synchronization: true
    stream_affinity: true
    stream_memory_pool: true
    tuning_timeout: 300
    tuning_metrics: ["accuracy", "latency"]
    kernel_tuning: true
    layer_fusion: true
    memory_reuse: true
    memory_scratch: true
    memory_workspace: true
    memory_alignment: 256
    memory_pool_max_size: 1073741824
    monitoring_interval: 1000
    monitoring_output: "segmentation_monitoring.log"
    monitoring_timeline: true
    monitoring_layers: true
    monitoring_kernels: true
    monitoring_memory: true
    monitoring_events: true
    debug_output: "segmentation_debug.log"
    debug_level: "info"
    debug_layers: false
    debug_kernels: false
    debug_memory: false
    debug_tensors: false
    debug_weights: false
    debug_activations: false
    version_compatibility: true
    api_compatibility: true
    plugin_compatibility: true
    format_compatibility: true
    parallel_threads: 8
    parallel_scheduling: "dynamic"
    parallel_synchronization: true
    parallel_affinity: true
    error_logging: true
    error_notification: true
    error_retry: true
    error_fallback: true
    error_timeout: 5000
    error_max_retries: 3
    memory_pinning: true
    memory_mapping: true
    memory_compression: false
    profiling_output: "segmentation_profiling.json"
    profiling_metrics: ["layer_time", "memory_usage", "throughput"]
    profiling_layers: true
    profiling_kernels: true
    profiling_memory: true
    profiling_timeline: true
    serialization_format: "binary"
    compression: true
    encryption: false
    checksum: true
    calibration_cache: "segmentation_calibration.cache"
}

// ============================================================================
// PIPELINE DEFINITIONS
// ============================================================================
pipeline perception_pipeline {
    stage preprocessing {
        input: "raw_image"
        output: "preprocessed_image"
        method: "preprocess_image"
        topic: /perception/preprocessing/result
        cuda_kernel: "image_filter"
    }
    
    stage classification {
        input: "preprocessed_image"
        output: "classification_result"
        method: "run_classification"
        onnx_model: "classification_model"
        topic: /perception/classification/result
    }
    
    stage detection {
        input: "preprocessed_image"
        output: "detection_result"
        method: "run_detection"
        onnx_model: "detection_model"
        topic: /perception/detection/result
    }
    
    stage segmentation {
        input: "preprocessed_image"
        output: "segmentation_result"
        method: "run_segmentation"
        onnx_model: "segmentation_model"
        topic: /perception/segmentation/result
    }
    
    stage fusion {
        input: "classification_result,detection_result,segmentation_result"
        output: "final_result"
        method: "fuse_results"
        topic: /perception/fusion/result
    }
}

pipeline navigation_pipeline {
    stage path_planning {
        input: "goal_pose,current_pose,map_data"
        output: "planned_path"
        method: "plan_path"
        topic: /navigation/planning/result
    }
    
    stage path_following {
        input: "planned_path,current_pose"
        output: "velocity_command"
        method: "follow_path"
        topic: /navigation/following/result
    }
    
    stage obstacle_avoidance {
        input: "velocity_command,sensor_data"
        output: "safe_velocity"
        method: "avoid_obstacles"
        topic: /navigation/avoidance/result
    }
}

// ============================================================================
// MAIN NODE CONFIGURATIONS
// ============================================================================

// Comprehensive main node with all features
node main_node {
    // Real-time configuration
    realtime: true
    realtime_priority: 80
    realtime_policy: "SCHED_FIFO"
    realtime_cpu: 0
    
    // Security configuration
    security: true
    security_enforce: true
    security_identity: "robot_identity"
    security_namespace: "/robot/secure"
    
    // Component configuration
    component: true
    component_name: "robot_component"
    component_namespace: "/robot/component"
    
    // Parameter server/client configuration
    parameter_server: true
    parameter_client: true
    // Node namespace
    namespace: /robot
    
    // Parameters with different types
    parameter int count = 0
    parameter double rate = 10.0
    parameter string name = "robot"
    parameter bool enabled = true
    parameter list array_coords = [1.0, 2.0, 3.0]
    parameter dict dict_config = {
        max_iterations: 100,
        timeout: 5.0,
        enabled: true
    }
    
    // ROS2 Publishers with QoS
    publisher /chatter: "std_msgs/msg/String" {
        qos {
            reliability: reliable
            history: keep_last
            depth: 10
            deadline: 1000
            lifespan: 5000
        }
        queue_size: 10
    }
    
    publisher /image_processed: "sensor_msgs/msg/Image" {
        qos {
            reliability: best_effort
            history: keep_last
            depth: 5
        }
        queue_size: 5
    }
    
    publisher /detections: "DetectionResult" {
        qos {
            reliability: reliable
            history: keep_last
            depth: 20
        }
        queue_size: 20
    }
    
    // ROS2 Subscribers with QoS
    subscriber /camera/image_raw: "sensor_msgs/msg/Image" {
        qos {
            reliability: best_effort
            history: keep_last
            depth: 5
        }
        queue_size: 5
    }
    
    subscriber /goal_pose: "geometry_msgs/msg/PoseStamped" {
        qos {
            reliability: reliable
            history: keep_last
            depth: 10
        }
        queue_size: 10
    }
    
    // ROS2 Services
    service /process_image: "ImageProcessing" {
        qos {
            reliability: reliable
            history: keep_last
            depth: 10
        }
    }
    
    // ROS2 Actions
    action /navigate_to_pose: "NavigationAction" {
        qos {
            reliability: reliable
            history: keep_last
            depth: 10
        }
    }
    
    // ROS2 Clients
    client /add_two_ints: "example_interfaces/srv/AddTwoInts"
    action_client /external_navigation: "nav2_msgs/action/NavigateToPose"
    
    // Timers
    timer main_timer: 1.0 {
        callback: "on_timer_callback"
        oneshot: false
        autostart: true
    }
    
    timer processing_timer: 0.1 {
        callback: "on_processing_callback"
        oneshot: false
        autostart: true
    }
    
    // Lifecycle configuration
    lifecycle {
        enabled: true
        autostart: false
        cleanup_on_shutdown: true
    }
    
    // Remaps
    remap from: /old/topic to: /new/topic
    remap from: /camera/image_raw to: /robot/camera/image_raw
    
    // Flags
    flag enable_logging: true
    flag debug_mode: false
    flag use_gpu: true
    
    // C++ methods
    method on_timer_callback {
        input: rclcpp::Time current_time
        code {
            auto message = std_msgs::msg::String();
            message.data = "Hello from robot! Count: " + std::to_string(count_);
            chatter_pub_->publish(message);
            count_++;
        }
    }
    
    method on_processing_callback {
        input: void
        code {
            if (enable_processing_) {
                process_latest_data();
            }
        }
    }
    
    method process_image {
        input: const sensor_msgs::msg::Image::SharedPtr image_msg
        output: std::vector<DetectionResult>& detections
        code {
            // Convert ROS image to OpenCV
            cv_bridge::CvImagePtr cv_ptr = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
            
            // Process with CUDA kernels
            if (use_gpu_) {
                process_image_gpu(cv_ptr->image, detections);
            } else {
                process_image_cpu(cv_ptr->image, detections);
            }
        }
    }
    
    method process_image_gpu {
        input: const cv::Mat& image
        output: std::vector<DetectionResult>& detections
        code {
            // Allocate GPU memory
            size_t image_size = image.total() * image.elemSize();
            uchar* d_input, *d_output;
            cudaMalloc(&d_input, image_size);
            cudaMalloc(&d_output, image_size);
            
            // Copy data to GPU
            cudaMemcpy(d_input, image.data, image_size, cudaMemcpyHostToDevice);
            
            // Launch kernel
            dim3 block_size(32, 32);
            dim3 grid_size((image.cols + block_size.x - 1) / block_size.x,
                          (image.rows + block_size.y - 1) / block_size.y);
            
            image_filter_kernel<<<grid_size, block_size>>>(d_input, d_output, image.cols, image.rows);
            
            // Copy result back
            cv::Mat processed_image(image.rows, image.cols, image.type());
            cudaMemcpy(processed_image.data, d_output, image_size, cudaMemcpyDeviceToHost);
            
            // Cleanup
            cudaFree(d_input);
            cudaFree(d_output);
            
            // Run ONNX inference
            run_detection_inference(processed_image, detections);
        }
    }
    
    method run_detection_inference {
        input: const cv::Mat& image
        output: std::vector<DetectionResult>& detections
        code {
            // Prepare input tensor
            std::vector<float> input_tensor;
            preprocess_for_detection(image, input_tensor);
            
            // Run ONNX inference
            std::vector<float> output_tensor;
            if (detection_session_->Run(input_tensor, output_tensor)) {
                postprocess_detections(output_tensor, detections);
            }
        }
    }
    
    // Use CUDA kernels
    use_kernel: "vector_add"
    use_kernel: "matrix_multiply"
    use_kernel: "image_filter"
    
    // ONNX model references
    onnx_model classification_model {
        input: "input" -> "float32[1,3,224,224]"
        output: "output" -> "float32[1,1000]"
        device: cuda
        optimization: tensorrt
    }
    
    onnx_model detection_model {
        input: "input" -> "float32[1,3,640,640]"
        output: "output" -> "float32[1,84,8400]"
        device: cuda
        optimization: tensorrt
    }
}

// Perception node with pipeline integration
node perception_node {
    namespace: /perception
    
    parameter bool enable_gpu = true
    parameter float confidence_threshold = 0.5
    parameter string model_path = "models/detection.onnx"
    
    subscriber /camera/image_raw: "sensor_msgs/msg/Image"
    publisher /detections: "DetectionResult"
    publisher /segmentation: "sensor_msgs/msg/Image"
    
    timer processing_timer: 0.033 {
        callback: "process_frame"
    }
    
    method process_frame {
        input: void
        code {
            if (latest_image_) {
                std::vector<DetectionResult> detections;
                process_image(latest_image_, detections);
                
                // Publish results
                for (const auto& detection : detections) {
                    auto msg = DetectionResult();
                    msg.id = detection.id;
                    msg.label = detection.label;
                    msg.confidence = detection.confidence;
                    msg.bbox_x = detection.bbox_x;
                    msg.bbox_y = detection.bbox_y;
                    msg.bbox_width = detection.bbox_width;
                    msg.bbox_height = detection.bbox_height;
                    detections_pub_->publish(msg);
                }
            }
        }
    }
    
}

// Pipeline integration for perception node
pipeline perception_pipeline {
    stage preprocessing {
        input: "raw_image"
        output: "preprocessed_image"
        method: "preprocess_image"
    }
    
    stage detection {
        input: "preprocessed_image"
        output: "detection_result"
        method: "run_detection"
        onnx_model: "detection_model"
    }
}

// Navigation node with action server
node navigation_node {
    namespace: /navigation
    
    parameter float max_velocity = 2.0
    parameter float goal_tolerance = 0.1
    parameter bool enable_obstacle_avoidance = true
    
    subscriber /goal_pose: "geometry_msgs/msg/PoseStamped"
    publisher /cmd_vel: "geometry_msgs/msg/Twist"
    publisher /path: "nav_msgs/msg/Path"
    
    action /navigate_to_pose: "NavigationAction"
    
    timer navigation_timer: 0.1 {
        callback: "navigation_step"
    }
    
    method navigation_step {
        input: void
        code {
            // Navigation logic implementation
            process_navigation_step();
        }
    }
}

// Safety monitoring node
node safety_node {
    namespace: /safety
    
    parameter float max_acceleration = 2.0
    parameter float emergency_stop_distance = 0.5
    parameter bool enable_emergency_stop = true
    
    subscriber /sensor_data: "sensor_msgs/msg/LaserScan"
    subscriber /cmd_vel: "geometry_msgs/msg/Twist"
    publisher /safe_cmd_vel: "geometry_msgs/msg/Twist"
    publisher /emergency_stop: "std_msgs/msg/Bool"
    
    timer safety_timer: 0.01 {
        callback: "safety_check"
    }
    
    method safety_check {
        input: void
        code {
            // Safety monitoring logic implementation
            process_safety_check();
        }
    }
}

// ============================================================================
// RAW C++ CODE BLOCKS
// ============================================================================
cpp: {
    // Additional C++ code that gets included in the generated files
    namespace robot_utils {
        // Utility functions
        template<typename T>
        T clamp(T value, T min, T max) {
            return std::max(min, std::min(max, value));
        }
        
        double radians_to_degrees(double radians) {
            return radians * 180.0 / M_PI;
        }
        
        double degrees_to_radians(double degrees) {
            return degrees * M_PI / 180.0;
        }
    }
}

// ============================================================================
// PACKAGE CONFIGURATION
// ============================================================================
package robot_package {
    name: "robot_package"
    version: "1.0.0"
    description: "Comprehensive robot package with all RoboDSL features"
    maintainer: "robot_team@example.com"
    license: "MIT"
    
    dependencies: [
        "rclcpp",
        "std_msgs",
        "sensor_msgs",
        "geometry_msgs",
        "nav2_msgs",
        "cv_bridge",
        "opencv2",
        "cuda",
        "onnxruntime",
        "tensorrt",
        "thrust",
        "cudnn",
        "cublas",
        "curand",
        "cufft",
        "npp",
        "nvml",
        "nvrtc",
        "cuda_driver",
        "cuda_runtime",
        "ament_cmake",
        "ament_cmake_auto",
        "ament_cmake_python",
        "ament_cmake_gtest",
        "ament_cmake_gmock"
    ]
    
    optional_dependencies: [
        "ament_lint_auto",
        "ament_lint_common",
        "ament_cmake_cppcheck",
        "ament_cmake_cpplint",
        "ament_cmake_uncrustify",
        "ament_cmake_xmllint"
    ]
    
    system_dependencies: [
        "cuda",
        "opencv",
        "onnxruntime",
        "tensorrt",
        "cudnn",
        "cublas",
        "thrust",
        "eigen3",
        "boost",
        "pcl",
        "vtk",
        "pcl_ros",
        "tf2",
        "tf2_ros",
        "tf2_geometry_msgs"
    ]
    
    dependency_parallel_download: true
    dependency_verification: true
    dependency_licenses: [
        "MIT",
        "Apache-2.0",
        "BSD-3-Clause",
        "GPL-3.0",
        "LGPL-2.1"
    ]
    
    // C++ node definitions within package
    cpp_node robot_cpp_node {
        namespace: /robot/cpp
        parameter int cpp_param = 42
        publisher /cpp_topic: "std_msgs/msg/String"
        subscriber /cpp_input: "std_msgs/msg/String"
    }
}
