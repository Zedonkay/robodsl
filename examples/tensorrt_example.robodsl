// TensorRT Optimization Example for RoboDSL
// This example shows how to use TensorRT optimization with ONNX models

// Project configuration
project_name: tensorrt_demo

// Global includes
include <rclcpp/rclcpp.hpp>
include <sensor_msgs/msg/image.hpp>
include <std_msgs/msg/float32_multi_array.hpp>
include <opencv2/opencv.hpp>

// ONNX Model with TensorRT Optimization
onnx_model resnet50 {
    input: "input" -> "float32[1,3,224,224]"
    output: "output" -> "float32[1,1000]"
    device: cuda
    optimization: tensorrt
}

// YOLO Model with TensorRT and FP16
onnx_model yolo_v8 {
    input: "images" -> "float32[1,3,640,640]"
    output: "output0" -> "float32[1,84,8400]"
    device: cuda
    optimization: tensorrt
}

// Main classification node
node image_classifier {
    // ROS2 interface
    subscriber /camera/image_raw: "sensor_msgs/msg/Image"
    publisher /classification/result: "std_msgs/msg/Float32MultiArray"
    
    // Parameters
    parameter string model_path = "resnet50.onnx"
    parameter bool enable_fp16 = true
    parameter int workspace_size = 1073741824  // 1GB
    
    // ONNX model reference
    onnx_model resnet50 {
        input: "input" -> "float32[1,3,224,224]"
        output: "output" -> "float32[1,1000]"
        device: cuda
        optimization: tensorrt
    }
    
    // Method to process images with TensorRT optimization
    method on_image(msg) {
        // Convert ROS2 image to OpenCV format
        cv::Mat cv_image = ros_image_to_cv(msg);
        
        // Preprocess image for ResNet50
        cv::Mat resized_image;
        cv::resize(cv_image, resized_image, cv::Size(224, 224));
        
        // Convert to float32 tensor
        std::vector<float> input_tensor = cv_mat_to_tensor(resized_image);
        
        // Run TensorRT-optimized inference
        std::vector<float> result;
        if (resnet50_inference_->run_inference_tensorrt(input_tensor, result)) {
            // Post-process results
            std::vector<int> top_indices = get_top_k_indices(result, 5);
            
            // Publish results
            publish_classification_result(top_indices);
        } else {
            RCLCPP_ERROR(this->get_logger(), "TensorRT inference failed");
        }
    }
}

// Object detection node with YOLO
node object_detector {
    // ROS2 interface
    subscriber /camera/image_raw: "sensor_msgs/msg/Image"
    publisher /detection/result: "std_msgs/msg/Float32MultiArray"
    
    // Parameters
    parameter string model_path = "yolo_v8.onnx"
    parameter float confidence_threshold = 0.5
    parameter float nms_threshold = 0.4
    
    // ONNX model reference
    onnx_model yolo_v8 {
        input: "images" -> "float32[1,3,640,640]"
        output: "output0" -> "float32[1,84,8400]"
        device: cuda
        optimization: tensorrt
    }
    
    // Method to process images with YOLO + TensorRT
    method on_image(msg) {
        // Convert ROS2 image to OpenCV format
        cv::Mat cv_image = ros_image_to_cv(msg);
        
        // Preprocess image for YOLO
        cv::Mat resized_image;
        cv::resize(cv_image, resized_image, cv::Size(640, 640));
        
        // Convert to float32 tensor
        std::vector<float> input_tensor = cv_mat_to_tensor(resized_image);
        
        // Run TensorRT-optimized YOLO inference
        std::vector<float> result;
        if (yolo_v8_inference_->run_inference_tensorrt(input_tensor, result)) {
            // Post-process YOLO results
            std::vector<Detection> detections = process_yolo_output(result, confidence_threshold);
            
            // Apply NMS
            std::vector<Detection> filtered_detections = apply_nms(detections, nms_threshold);
            
            // Publish results
            publish_detection_result(filtered_detections);
        } else {
            RCLCPP_ERROR(this->get_logger(), "YOLO TensorRT inference failed");
        }
    }
}

// Pipeline example with TensorRT optimization
pipeline vision_pipeline {
    stage preprocessing {
        input: "raw_image"
        output: "preprocessed_image"
        method: "preprocess_image"
        topic: /preprocessing/result
    }
    
    stage classification {
        input: "preprocessed_image"
        output: "classification_result"
        method: "run_classification"
        onnx_model: "resnet50"
        topic: /classification/result
    }
    
    stage detection {
        input: "preprocessed_image"
        output: "detection_result"
        method: "run_detection"
        onnx_model: "yolo_v8"
        topic: /detection/result
    }
    
    stage fusion {
        input: "classification_result,detection_result"
        output: "final_result"
        method: "fuse_results"
        topic: /fusion/result
    }
}

// CUDA kernels for preprocessing
cuda_kernels {
    kernel normalize_image {
        input: float* input_data, int width, int height, int channels
        output: float* output_data
        
        block_size: (16, 16, 1)
        grid_size: (width/16 + 1, height/16 + 1, 1)
        
        include <cuda_runtime.h>
        include <device_launch_parameters.h>
        
        code {
            __global__ void normalize_image(const float* input, float* output, int width, int height, int channels) {
                int x = blockIdx.x * blockDim.x + threadIdx.x;
                int y = blockIdx.y * blockDim.y + threadIdx.y;
                
                if (x < width && y < height) {
                    int idx = (y * width + x) * channels;
                    
                    // Normalize to [0, 1] range
                    for (int c = 0; c < channels; c++) {
                        output[idx + c] = input[idx + c] / 255.0f;
                    }
                }
            }
        }
    }
    
    kernel resize_image {
        input: float* input_data, int input_width, int input_height, float* output_data, int output_width, int output_height
        output: float* resized_data
        
        block_size: (16, 16, 1)
        grid_size: (output_width/16 + 1, output_height/16 + 1, 1)
        
        include <cuda_runtime.h>
        include <device_launch_parameters.h>
        
        code {
            __global__ void resize_image(const float* input, float* output, 
                                       int input_width, int input_height,
                                       int output_width, int output_height) {
                int x = blockIdx.x * blockDim.x + threadIdx.x;
                int y = blockIdx.y * blockDim.y + threadIdx.y;
                
                if (x < output_width && y < output_height) {
                    // Simple nearest neighbor interpolation
                    int src_x = (x * input_width) / output_width;
                    int src_y = (y * input_height) / output_height;
                    
                    int src_idx = src_y * input_width + src_x;
                    int dst_idx = y * output_width + x;
                    
                    output[dst_idx] = input[src_idx];
                }
            }
        }
    }
}

// Simulation configuration for testing
simulation gazebo {
    world {
        physics_engine: "ode"
        gravity: (0, 0, -9.81)
        max_step_size: 0.001
        real_time_factor: 1.0
    }
    
    robot camera_robot {
        model_file: "package://gazebo_ros/models/camera/model.sdf"
        namespace: /camera
        initial_pose: (0, 0, 1, 0, 0, 0)
    }
}

// Dynamic parameters for runtime configuration
dynamic_parameters {
    parameter float tensorrt_workspace_size = 1073741824 {
        description: "TensorRT workspace size in bytes"
    }
    
    parameter bool enable_tensorrt_fp16 = true {
        description: "Enable TensorRT FP16 optimization"
    }
    
    parameter bool enable_tensorrt_int8 = false {
        description: "Enable TensorRT INT8 quantization"
    }
    
    parameter string tensorrt_cache_path = "./trt_cache" {
        description: "TensorRT engine cache directory"
    }
} 