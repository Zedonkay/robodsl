// ROS2 and CUDA Integration Example
// This example demonstrates a complete ROS2 node with CUDA acceleration
// for image processing in a robotics application

// Include necessary message types
include <sensor_msgs/msg/image.hpp>
include <std_msgs/msg/header.hpp>
include <cv_bridge/cv_bridge.h>

// Define a custom message for processed image results
msg ProcessedImage {
    std_msgs/msg/Header header
    sensor_msgs/msg/Image original_image
    sensor_msgs/msg/Image processed_image
    float processing_time_ms
    string processing_device
}

// Define a CUDA kernel for image processing
cuda_kernels {
    kernel edge_detection {
        // Input parameters
        input uint8_t* input_image
        input int width
        input int height
        input int channels
        output uint8_t* output_image
        
        // Kernel configuration
        block_size = (16, 16, 1)
        grid_size = ((width + 15) / 16, (height + 15) / 16, 1)
        
        // Kernel code for Sobel edge detection
        code {
            __global__ void edge_detection_kernel(
                const uint8_t* input,
                uint8_t* output,
                const int width,
                const int height,
                const int channels) {
                
                // 2D thread and block indices
                int x = blockIdx.x * blockDim.x + threadIdx.x;
                int y = blockIdx.y * blockDim.y + threadIdx.y;
                
                // Check if within image bounds
                if (x >= 1 && x < width - 1 && y >= 1 && y < height - 1) {
                    // For each channel
                    for (int c = 0; c < channels; ++c) {
                        // Calculate indices
                        int idx = (y * width + x) * channels + c;
                        
                        // Get neighboring pixels
                        float gx = -1.0f * input[((y-1)*width + (x-1))*channels + c] + 
                                   1.0f * input[((y-1)*width + (x+1))*channels + c] +
                                  -2.0f * input[(y*width + (x-1))*channels + c] +
                                   2.0f * input[(y*width + (x+1))*channels + c] +
                                  -1.0f * input[((y+1)*width + (x-1))*channels + c] +
                                   1.0f * input[((y+1)*width + (x+1))*channels + c];
                        
                        float gy = -1.0f * input[((y-1)*width + (x-1))*channels + c] + 
                                  -2.0f * input[((y-1)*width + x)*channels + c] +
                                  -1.0f * input[((y-1)*width + (x+1))*channels + c] +
                                   1.0f * input[((y+1)*width + (x-1))*channels + c] +
                                   2.0f * input[((y+1)*width + x)*channels + c] +
                                   1.0f * input[((y+1)*width + (x+1))*channels + c];
                        
                        // Calculate gradient magnitude
                        float magnitude = sqrtf(gx * gx + gy * gy);
                        
                        // Threshold and store result
                        output[idx] = (magnitude > 128.0f) ? 255 : 0;
                    }
                } else if (x < width && y < height) {
                    // Border handling: just copy the input
                    for (int c = 0; c < channels; ++c) {
                        int idx = (y * width + x) * channels + c;
                        output[idx] = input[idx];
                    }
                }
            }
        }
    }
}

// Main ROS2 node with CUDA acceleration
node image_processor {
    // Enable lifecycle management
    lifecycle: true
    
    // Namespace for organization
    namespace: /robot1/perception
    
    // Parameters
    parameters {
        // Enable/disable CUDA acceleration
        bool use_cuda {
            default: true
            description: "Enable CUDA acceleration for image processing"
        }
        
        // Edge detection threshold
        float edge_threshold {
            default: 128.0
            min: 0.0
            max: 255.0
            description: "Edge detection threshold (0-255)"
        }
        
        // Image processing rate
        double processing_rate {
            default: 30.0
            min: 1.0
            max: 60.0
            description: "Image processing rate in Hz"
        }
    }
    
    // QoS profile for image transport
    qos_profile image_transport_qos {
        reliability: reliable
        durability: volatile
        history: keep_last
        depth: 5
    }
    
    // Subscriber for input images
    subscriber /camera/image_raw sensor_msgs/msg/Image @image_transport_qos {
        on_message: on_image_received
    }
    
    // Publisher for processed images
    publisher /processed_image ProcessedImage @image_transport_qos
    
    // Timer for periodic processing
    timer 1.0/params.processing_rate {
        if (latest_image) {
            process_image(latest_image)
        }
    }
    
    // Member variables
    sensor_msgs/msg/Image latest_image
    bool processing = false
    
    // Lifecycle callbacks
    on_configure {
        // Initialize CUDA if available and enabled
        if (params.use_cuda) {
            try {
                int device_count = 0
                cudaGetDeviceCount(&device_count)
                if (device_count > 0) {
                    cudaSetDevice(0)  // Use first available device
                    print("CUDA acceleration enabled on device 0")
                } else {
                    print("Warning: No CUDA-capable devices found. Falling back to CPU.")
                    params.use_cuda = false
                }
            } catch (const std::exception& e) {
                print("Error initializing CUDA: ", e.what())
                params.use_cuda = false
            }
        }
        
        return SUCCESS
    }
    
    on_activate {
        // Activate publishers
        pub.activate()
        return SUCCESS
    }
    
    on_deactivate {
        // Deactivate publishers
        pub.deactivate()
        return SUCCESS
    }
    
    on_cleanup {
        // Cleanup resources
        latest_image = null
        return SUCCESS
    }
    
    // Callback for incoming images
    function on_image_received(msg) {
        // Store the latest image for processing
        latest_image = msg
    }
    
    // Image processing function
    function process_image(image_msg) {
        if (processing) {
            return  // Skip if already processing
        }
        
        processing = true
        
        try {
            auto start_time = now()
            
            // Convert ROS image to OpenCV format
            auto cv_ptr = cv_bridge::toCvCopy(image_msg, "bgr8")
            cv::Mat image = cv_ptr->image
            
            // Process the image
            cv::Mat processed_image
            
            if (params.use_cuda) {
                // Process on GPU using CUDA
                processed_image = process_image_cuda(image)
            } else {
                // Process on CPU using OpenCV
                cv::Mat gray, grad_x, grad_y, abs_grad_x, abs_grad_y
                
                // Convert to grayscale
                cv::cvtColor(image, gray, cv::COLOR_BGR2GRAY)
                
                // Calculate gradients
                cv::Sobel(gray, grad_x, CV_16S, 1, 0, 3, 1, 0, cv::BORDER_DEFAULT)
                cv::Sobel(gray, grad_y, CV_16S, 0, 1, 3, 1, 0, cv::BORDER_DEFAULT)
                
                // Convert back to 8-bit
                cv::convertScaleAbs(grad_x, abs_grad_x)
                cv::convertScaleAbs(grad_y, abs_grad_y)
                
                // Combine gradients
                cv::addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, processed_image)
                
                // Apply threshold
                cv::threshold(processed_image, processed_image, 
                             params.edge_threshold, 255, cv::THRESH_BINARY)
            }
            
            // Create output message
            auto result_msg = ProcessedImage()
            result_msg.header = image_msg.header
            result_msg.header.stamp = now()
            result_msg.original_image = image_msg
            
            // Convert processed image back to ROS format
            auto cv_processed = cv_bridge::CvImage(
                image_msg.header,
                "mono8",
                processed_image
            ).toImageMsg()
            
            result_msg.processed_image = cv_processed
            result_msg.processing_time_ms = (now() - start_time).seconds() * 1000.0
            result_msg.processing_device = params.use_cuda ? "GPU" : "CPU"
            
            // Publish the result
            pub.publish(result_msg)
            
        } catch (const std::exception& e) {
            print("Error processing image: ", e.what())
        }
        
        processing = false
    }
    
    // CUDA image processing function
    function process_image_cuda(cv::Mat& image) -> cv::Mat {
        // Allocate input and output buffers on device
        size_t image_size = image.rows * image.cols * image.channels()
        
        // Allocate device memory
        uint8_t* d_input = nullptr
        uint8_t* d_output = nullptr
        
        cudaMalloc(&d_input, image_size)
        cudaMalloc(&d_output, image_size)
        
        // Copy input image to device
        cudaMemcpy(d_input, image.data, image_size, cudaMemcpyHostToDevice)
        
        // Launch CUDA kernel
        launch_kernel(
            "edge_detection", 
            0,  // Default stream
            d_input,
            image.cols,
            image.rows,
            image.channels(),
            d_output
        )
        
        // Allocate output image
        cv::Mat result(image.rows, image.cols, CV_8UC1)
        
        // Copy result back to host
        cudaMemcpy(result.data, d_output, image.rows * image.cols, cudaMemcpyDeviceToHost)
        
        // Free device memory
        cudaFree(d_input)
        cudaFree(d_output)
        
        return result
    }
}

// Example launch configuration
launch {
    // Set the default log level
    set_parameter("log_level", "info")
    
    // Launch the image processor node
    node image_processor {
        // Override default parameters if needed
        parameters {
            use_cuda: true
            edge_threshold: 150.0
            processing_rate: 30.0
        }
        
        // Remap input topic
        remap {
            from: /camera/image_raw
            to: /robot1/camera/color/image_raw
        }
    }
    
    // Launch a simple image publisher for testing
    node test_image_publisher {
        package: "image_tools"
        executable: "cam2image"
        parameters: [
            "--ros-args -p publish_rate:=30.0"
        ]
        remap: [
            "output_webcam:=/robot1/camera/color/image_raw"
        ]
    }
    
    // Launch RViz for visualization
    node rviz {
        package: "rviz2"
        executable: "rviz2"
        arguments: [
            "-d", "$(find-pkg-share robodsl)/rviz/image_processor.rviz"
        ]
    }
}
