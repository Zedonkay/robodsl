// Generated by RoboDSL - DO NOT EDIT
// CUDA Kernel: mppi_rollout

#ifndef MPPI_ROLLOUT_KERNEL_H_
#define MPPI_ROLLOUT_KERNEL_H_

#include "cuda_utils.h"
#include <cuda_runtime.h>
#include <map>
#include <memory>
#include <stdexcept>
#include <string>
#include <vector>

// Kernel configuration
struct Mppi_rolloutKernelConfig {
    dim3 block_size = {256, 1, 1};
    dim3 grid_size = {1, 1, 1};
    size_t shared_mem_bytes = 0;
    bool use_managed_memory = false;
};

class Mppi_rolloutKernel {
public:
    Mppi_rolloutKernel();
    ~Mppi_rolloutKernel();
    
    // Configure kernel with parameters
    void configure(const std::map<std::string, std::string>& params);
    
    // Process data using CUDA kernel
    void process();
    
    // Get configuration
    const Mppi_rolloutKernelConfig& get_config() const { return config_; }
    
private:
    // Kernel launch function
    void launch_kernel();
    
    // Configuration
    Mppi_rolloutKernelConfig config_;
    
    // Device memory pointers
    std::vector<void*> device_ptrs_;
    
    // Thrust device vectors (if using Thrust)
    // No Thrust vectors
    
    // Allocate device memory
    template<typename T>
    T* allocate_device_memory(size_t count);
    
    // Free all device memory
    void free_device_memory();
    
    // CUDA error checking
    void check_cuda_error(cudaError_t err, const std::string& msg) const;
};

// Kernel function declaration
extern "C" __global__ void mppi_rollout_kernel();


// Helper macros for kernel launches
#define LAUNCH_MPPI_ROLLOUT_KERNEL(    grid, block, shared_mem, stream, ...)     mppi_rollout_kernel<<<grid, block, shared_mem, stream>>>(__VA_ARGS__);

#endif // MPPI_ROLLOUT_KERNEL_H_
