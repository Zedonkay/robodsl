// Generated by RoboDSL - DO NOT EDIT

#ifndef {{ include_guard }}
#define {{ include_guard }}

// Standard includes
#include <memory>
#include <vector>
#include <string>
#include <functional>
#include <chrono>
#include <map>
#include <algorithm>

// CUDA includes
#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <thrust/device_vector.h>
#include <thrust/host_vector.h>

// ROS2 includes
#include <rclcpp/rclcpp.hpp>
#include <std_msgs/msg/float32_multi_array.hpp>
#include <sensor_msgs/msg/image.hpp>

// CUDA kernel header
#include "{{ include_path }}"

namespace {{ namespace }} {

/**
 * @brief ROS2-compatible CUDA kernel wrapper for {{ kernel_name }}
 * 
 * This class provides a high-level interface for using CUDA kernels in ROS2 nodes.
 * It handles memory management, error checking, and provides convenient methods
 * for processing ROS2 messages.
 */
class {{ kernel_name }}Wrapper {
public:
    /**
     * @brief Construct a new {{ kernel_name }} Wrapper object
     * 
     * @param node ROS2 node for logging and parameter access
     * @param stream CUDA stream for asynchronous operations (nullptr for default)
     */
    explicit {{ kernel_name }}Wrapper(
        rclcpp::Node* node = nullptr,
        cudaStream_t stream = nullptr
    ) : node_(node), stream_(stream), device_id_(0), initialized_(false), allocated_size_(0) {
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), "Creating {{ kernel_name }}Wrapper");
        }
    }
    
    /**
     * @brief Destroy the {{ kernel_name }} Wrapper object
     * 
     * Frees all allocated device memory and CUDA resources.
     */
    ~{{ kernel_name }}Wrapper() {
        freeDeviceMemory();
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), "Destroying {{ kernel_name }}Wrapper");
        }
    }
    
    // Delete copy constructor and assignment operator
    {{ kernel_name }}Wrapper(const {{ kernel_name }}Wrapper&) = delete;
    {{ kernel_name }}Wrapper& operator=(const {{ kernel_name }}Wrapper&) = delete;
    
    // Allow move constructor and assignment
    {{ kernel_name }}Wrapper({{ kernel_name }}Wrapper&& other) noexcept
        : node_(other.node_), stream_(other.stream_), device_id_(other.device_id_),
          initialized_(other.initialized_), allocated_size_(other.allocated_size_),
          input_sizes_(std::move(other.input_sizes_)), output_sizes_(std::move(other.output_sizes_)),
          last_error_(std::move(other.last_error_)), perf_stats_(other.perf_stats_),
          progress_callback_(std::move(other.progress_callback_)) {
        
        // Move device memory pointers
        {% for member in members %}
        {{ member.name }} = other.{{ member.name }};
        other.{{ member.name }} = nullptr;
        {% endfor %}
        
        other.initialized_ = false;
        other.allocated_size_ = 0;
    }
    
    {{ kernel_name }}Wrapper& operator=({{ kernel_name }}Wrapper&& other) noexcept {
        if (this != &other) {
            freeDeviceMemory();
            
            node_ = other.node_;
            stream_ = other.stream_;
            device_id_ = other.device_id_;
            initialized_ = other.initialized_;
            allocated_size_ = other.allocated_size_;
            input_sizes_ = std::move(other.input_sizes_);
            output_sizes_ = std::move(other.output_sizes_);
            last_error_ = std::move(other.last_error_);
            perf_stats_ = other.perf_stats_;
            progress_callback_ = std::move(other.progress_callback_);
            
            // Move device memory pointers
            {% for member in members %}
            {{ member.name }} = other.{{ member.name }};
            other.{{ member.name }} = nullptr;
            {% endfor %}
            
            other.initialized_ = false;
            other.allocated_size_ = 0;
        }
        return *this;
    }
    
    /**
     * @brief Initialize the wrapper with CUDA device
     * 
     * @param device_id CUDA device ID to use
     * @return true if initialization was successful
     */
    bool initialize(int device_id = 0) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        device_id_ = device_id;
        
        // Set CUDA device
        if (!checkCudaError(cudaSetDevice(device_id_), "cudaSetDevice")) {
            return false;
        }
        
        // Get device properties
        cudaDeviceProp prop;
        if (!checkCudaError(cudaGetDeviceProperties(&prop, device_id_), "cudaGetDeviceProperties")) {
            return false;
        }
        
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), 
                "Initialized {{ kernel_name }}Wrapper on device %d: %s", 
                device_id_, prop.name);
        }
        
        initialized_ = true;
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    /**
     * @brief Process data from ROS2 Float32MultiArray message
     * 
     * @param input_msg Input ROS2 message
     * @param output_msg Output ROS2 message (will be populated)
     * @return true if processing was successful
     */
    bool processMessage(
        const std_msgs::msg::Float32MultiArray::SharedPtr& input_msg,
        std_msgs::msg::Float32MultiArray::SharedPtr& output_msg
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Convert ROS2 message to vector
        std::vector<float> input_data(input_msg->data.begin(), input_msg->data.end());
        std::vector<float> output_data;
        
        // Process data
        if (!processData(input_data, output_data)) {
            return false;
        }
        
        // Convert back to ROS2 message
        output_msg = std::make_shared<std_msgs::msg::Float32MultiArray>();
        output_msg->data = output_data;
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process data from ROS2 Image message
     * 
     * @param input_msg Input ROS2 image message
     * @param output_msg Output ROS2 image message (will be populated)
     * @return true if processing was successful
     */
    bool processImage(
        const sensor_msgs::msg::Image::SharedPtr& input_msg,
        sensor_msgs::msg::Image::SharedPtr& output_msg
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Convert image data to float vector
        std::vector<float> input_data;
        size_t pixel_count = input_msg->width * input_msg->height;
        
        if (input_msg->encoding == "rgb8" || input_msg->encoding == "bgr8") {
            input_data.resize(pixel_count * 3);
            for (size_t i = 0; i < pixel_count * 3; ++i) {
                input_data[i] = static_cast<float>(input_msg->data[i]) / 255.0f;
            }
        } else if (input_msg->encoding == "mono8") {
            input_data.resize(pixel_count);
            for (size_t i = 0; i < pixel_count; ++i) {
                input_data[i] = static_cast<float>(input_msg->data[i]) / 255.0f;
            }
        } else {
            last_error_ = "Unsupported image encoding: " + input_msg->encoding;
            return false;
        }
        
        std::vector<float> output_data;
        if (!processData(input_data, output_data)) {
            return false;
        }
        
        // Convert back to image message
        output_msg = std::make_shared<sensor_msgs::msg::Image>(*input_msg);
        output_msg->data.resize(output_data.size());
        
        for (size_t i = 0; i < output_data.size(); ++i) {
            output_msg->data[i] = static_cast<uint8_t>(std::clamp(output_data[i] * 255.0f, 0.0f, 255.0f));
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process raw data vectors
     * 
     * @param input_data Input data vector
     * @param output_data Output data vector (will be populated)
     * @return true if processing was successful
     */
    bool processData(
        const std::vector<float>& input_data,
        std::vector<float>& output_data
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Allocate device memory if needed
        if (!allocateDeviceMemory(input_data.size(), input_data.size())) {
            return false;
        }
        
        // Copy data to device
        if (!copyToDevice(input_data)) {
            return false;
        }
        
        // Launch kernel
        if (!launchKernel(input_data.size())) {
            return false;
        }
        
        // Copy results back
        if (!copyFromDevice(output_data)) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process data with custom parameters
     * 
     * @param input_data Input data vector
     * @param output_data Output data vector (will be populated)
     * @param parameters Custom kernel parameters
     * @return true if processing was successful
     */
    bool processDataWithParameters(
        const std::vector<float>& input_data,
        std::vector<float>& output_data,
        const {{ param_type }}& parameters
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Allocate device memory if needed
        if (!allocateDeviceMemory(input_data.size(), input_data.size())) {
            return false;
        }
        
        // Copy data to device
        if (!copyToDevice(input_data)) {
            return false;
        }
        
        // Launch kernel with parameters
        if (!launchKernelWithParameters(input_data.size(), parameters)) {
            return false;
        }
        
        // Copy results back
        if (!copyFromDevice(output_data)) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Get the last error message
     * 
     * @return std::string Last error message or empty string if no error
     */
    const std::string& getLastError() const { return last_error_; }
    
    /**
     * @brief Check if the wrapper is properly initialized
     * 
     * @return true if initialized and ready to use
     */
    bool isInitialized() const { return initialized_; }
    
    /**
     * @brief Get performance statistics
     * 
     * @return std::map<std::string, double> Performance metrics
     */
    std::map<std::string, double> getPerformanceStats() const {
        std::map<std::string, double> stats;
        
        if (perf_stats_.call_count > 0) {
            stats["total_time_ms"] = perf_stats_.total_time.count() / 1000.0;
            stats["kernel_time_ms"] = perf_stats_.kernel_time.count() / 1000.0;
            stats["memory_time_ms"] = perf_stats_.memory_time.count() / 1000.0;
            stats["call_count"] = static_cast<double>(perf_stats_.call_count);
            stats["error_count"] = static_cast<double>(perf_stats_.error_count);
            stats["avg_time_per_call_ms"] = (perf_stats_.total_time.count() / 1000.0) / perf_stats_.call_count;
        }
        
        return stats;
    }
    
    /**
     * @brief Reset performance statistics
     */
    void resetPerformanceStats() {
        perf_stats_ = PerformanceStats{};
    }
    
    /**
     * @brief Set callback for progress updates
     * 
     * @param callback Function to call with progress updates (0.0 to 1.0)
     */
    void setProgressCallback(std::function<void(float)> callback) {
        progress_callback_ = callback;
    }

private:
    // ROS2 node for logging and parameters
    rclcpp::Node* node_;
    
    // CUDA resources
    cudaStream_t stream_;
    int device_id_;
    bool initialized_;
    
    // Device memory pointers
    {% for member in members %}
    {{ member.type }}* {{ member.name }} = nullptr;  //!< Device memory for {{ member.original_name }}
    {% endfor %}
    
    // Memory management
    size_t allocated_size_ = 0;
    std::vector<size_t> input_sizes_;
    std::vector<size_t> output_sizes_;
    
    // Error handling
    std::string last_error_;
    
    // Performance tracking
    struct PerformanceStats {
        std::chrono::microseconds total_time{0};
        std::chrono::microseconds kernel_time{0};
        std::chrono::microseconds memory_time{0};
        size_t call_count = 0;
        size_t error_count = 0;
    } perf_stats_;
    
    // Progress callback
    std::function<void(float)> progress_callback_;
    
    // Internal methods
    bool checkCudaError(cudaError_t status, const std::string& context) {
        if (status != cudaSuccess) {
            last_error_ = context + ": " + cudaGetErrorString(status);
            perf_stats_.error_count++;
            
            if (node_) {
                RCLCPP_ERROR(node_->get_logger(), "%s", last_error_.c_str());
            }
            return false;
        }
        return true;
    }
    
    bool allocateDeviceMemory(size_t input_size, size_t output_size) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Free existing memory if sizes don't match
        if (allocated_size_ != input_size) {
            freeDeviceMemory();
        }
        
        if (allocated_size_ == 0) {
            {% for member in members %}
            cudaError_t status = cudaMalloc(&{{ member.name }}, input_size * sizeof({{ member.type }}));
            if (!checkCudaError(status, "cudaMalloc for {{ member.name }}")) {
                return false;
            }
            {% endfor %}
            
            allocated_size_ = input_size;
            input_sizes_.push_back(input_size);
            output_sizes_.push_back(output_size);
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    void freeDeviceMemory() {
        {% for member in members %}
        if ({{ member.name }}) {
            cudaFree({{ member.name }});
            {{ member.name }} = nullptr;
        }
        {% endfor %}
        
        allocated_size_ = 0;
        input_sizes_.clear();
        output_sizes_.clear();
    }
    
    bool copyToDevice(const std::vector<float>& input_data) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        {% for member in members %}
        cudaError_t status = cudaMemcpy({{ member.name }}, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for {{ member.name }}")) {
            return false;
        }
        {% endfor %}
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool copyFromDevice(std::vector<float>& output_data) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        output_data.resize(allocated_size_);
        
        {% for member in members %}
        cudaError_t status = cudaMemcpy(output_data.data(), {{ member.name }}, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for {{ member.name }}")) {
            return false;
        }
        {% endfor %}
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool launchKernel(size_t num_elements) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Calculate grid and block dimensions
        int block_size = {{ block_size }};
        int grid_size = (num_elements + block_size - 1) / block_size;
        
        // Launch kernel
        {{ kernel_name }}_kernel<<<grid_size, block_size, {{ shared_memory }}, stream_>>>(
            {% for member in members %}
            {{ member.name }}{% if not loop.last %},{% endif %}
            {% endfor %}
            num_elements
        );
        
        // Check for kernel launch errors
        if (!checkCudaError(cudaGetLastError(), "Kernel launch")) {
            return false;
        }
        
        // Synchronize if no stream
        if (stream_ == nullptr) {
            if (!checkCudaError(cudaDeviceSynchronize(), "cudaDeviceSynchronize")) {
                return false;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.kernel_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool launchKernelWithParameters(size_t num_elements, const {{ param_type }}& parameters) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Calculate grid and block dimensions
        int block_size = {{ block_size }};
        int grid_size = (num_elements + block_size - 1) / block_size;
        
        // Launch kernel with parameters
        {{ kernel_name }}_kernel<<<grid_size, block_size, {{ shared_memory }}, stream_>>>(
            {% for member in members %}
            {{ member.name }}{% if not loop.last %},{% endif %}
            {% endfor %}
            num_elements,
            parameters
        );
        
        // Check for kernel launch errors
        if (!checkCudaError(cudaGetLastError(), "Kernel launch with parameters")) {
            return false;
        }
        
        // Synchronize if no stream
        if (stream_ == nullptr) {
            if (!checkCudaError(cudaDeviceSynchronize(), "cudaDeviceSynchronize")) {
                return false;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.kernel_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
};

// Factory function for creating wrapper instances
inline std::unique_ptr<{{ kernel_name }}Wrapper> create{{ kernel_name }}Wrapper(
    rclcpp::Node* node = nullptr,
    cudaStream_t stream = nullptr) {
    return std::make_unique<{{ kernel_name }}Wrapper>(node, stream);
}

} // namespace {{ namespace }}

#endif // {{ include_guard }}
