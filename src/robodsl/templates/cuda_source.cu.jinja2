// Generated by RoboDSL - DO NOT EDIT

#include "{{ kernel.name }}_kernel.cuh"
#include <stdexcept>
#include <string>
#include <vector>
#include <cassert>

// CUDA error checking macro
#define CUDA_CHECK(call) \
    do { \
        cudaError_t err = (call); \
        if (err != cudaSuccess) { \
            throw std::runtime_error( \
                std::string("CUDA error: ") + cudaGetErrorString(err) + " at " + __FILE__ + ":" + std::to_string(__LINE__)); \
        } \
    } while(0)

// Kernel parameters
constexpr int BLOCK_SIZE_X = {{ block_x }};
constexpr int BLOCK_SIZE_Y = {{ block_y }};
constexpr int BLOCK_SIZE_Z = {{ block_z }};


// Kernel function for {{ kernel.name }}
// NOTE: Per CUDA requirements and RoboDSL grammar, kernel functions must be free functions (not class or namespace members)
__global__ void {{ kernel.name }}_kernel(
    {%- for input_def in kernel.inputs %}
    const {{ input_def.type }}* {{ input_def.name }}{% if not loop.last or kernel.outputs or true %},{% endif %}
    {%- endfor %}
    {%- for output_def in kernel.outputs %}
    {{ output_def.type }}* {{ output_def.name }}{% if not loop.last %},{% endif %}
    {%- endfor %}
    int num_elements
) {
    // User's kernel code
    {{ kernel.code | indent(4) }}
}

// Implementation of {{ class_name }} methods
{{ class_impl | safe }}

// Kernel launch wrapper
void {{ class_name }}::process(
    {%- for param in input_params %}
    {{ param }}{% if not loop.last or output_params %}, {% endif %}
    {%- endfor %}
    {%- for param in output_params %}
    {{ param }}{% if not loop.last %}, {% endif %}
    {%- endfor %}
) {
    // Free any previously allocated device memory
    free_device_memory();
    
    try {
        // Copy input data to device
        {{ mem_copies_h2d | safe }}
        
        // Launch kernel
        size_t num_elements = input_0.size();  // Assuming at least one input
        const int num_blocks = (num_elements + BLOCK_SIZE_X - 1) / BLOCK_SIZE_X;
        const dim3 block_dim(BLOCK_SIZE_X, BLOCK_SIZE_Y, BLOCK_SIZE_Z);
        const dim3 grid_dim(num_blocks, 1, 1);
        
        // Launch kernel
        {{ kernel.name }}_kernel<<<grid_dim, block_dim, {{ kernel.shared_mem_bytes }}>>>(
            {%- for i in range(kernel.inputs|length) %}
            d_input_{{ i }}{% if not loop.last or kernel.outputs %}, {% endif %}
            {%- endfor %}
            {%- for i in range(kernel.outputs|length) %}
            d_output_{{ i }}{% if not loop.last %}, {% endif %}
            {%- endfor %}
            num_elements
        );
        CUDA_CHECK(cudaGetLastError());
        CUDA_CHECK(cudaDeviceSynchronize());
        
        // Copy results back to host
        {{ mem_copies_d2h | safe }}
        
    } catch (const std::exception& e) {
        // Clean up and rethrow
        free_device_memory();
        throw std::runtime_error(std::string("Error in {{ kernel.name }}: ") + e.what());
    }
}
