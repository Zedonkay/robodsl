// Generated by RoboDSL - DO NOT EDIT

#include "{{ include_path }}"
#include <memory>

{% if namespace %}
namespace {{ namespace }} {
{% endif %}

{{ class_name }}::{{ class_name }}(const rclcpp::NodeOptions& options)
: {{ base_class }}("{{ node_name }}", options)
{
    // Initialize parameters
    {% for param in parameters %}
    this->declare_parameter<{{ param.type }}>("{{ param.name }}", {{ param.default_value }});
    {% endfor %}

    // Create publishers
    {% for pub in publishers %}
    {
        rclcpp::QoS qos({{ pub.qos.depth | default(10) }});
        {% if pub.qos.reliability %}
        qos.reliability(rclcpp::{{ pub.qos.reliability }});
        {% endif %}
        {% if pub.qos.durability %}
        qos.durability(rclcpp::{{ pub.qos.durability }});
        {% endif %}
        {{ pub.name }}_pub_ = this->create_publisher<{{ pub.msg_type }}>(
            "{{ pub.topic }}", qos);
    }
    {% endfor %}

    // Create subscribers
    {% for sub in subscribers %}
    {
        rclcpp::QoS qos({{ sub.qos.depth | default(10) }});
        {% if sub.qos.reliability %}
        qos.reliability(rclcpp::{{ sub.qos.reliability }});
        {% endif %}
        auto callback = std::bind(
            &{{ class_name }}::{{ sub.callback_name }}, 
            this, 
            std::placeholders::_1
        );
        {{ sub.name }}_sub_ = this->create_subscription<{{ sub.msg_type }}>(
            "{{ sub.topic }}", 
            qos, 
            callback
        );
    }
    {% endfor %}

    // Create services with proper error handling
    {% for srv in services %}
    {
        try {
            auto callback = [this](
                const std::shared_ptr<{{ srv.srv_type }}::Request> request,
                std::shared_ptr<{{ srv.srv_type }}::Response> response
            ) {
                try {
                    return this->{{ srv.callback_name }}(request, response);
                } catch (const std::exception& e) {
                    RCLCPP_ERROR(this->get_logger(), 
                        "Exception in service callback {{ srv.callback_name }}: %s", e.what());
                    response->success = false;
                    response->message = std::string("Service error: ") + e.what();
                } catch (...) {
                    RCLCPP_ERROR(this->get_logger(), 
                        "Unknown exception in service callback {{ srv.callback_name }}");
                    response->success = false;
                    response->message = "Unknown service error";
                }
            };
            
            {{ srv.name }}_srv_ = this->create_service<{{ srv.srv_type }}>(
                "{{ srv.service }}", 
                callback,
                rclcpp::ServicesQoS().reliable()
            );
            
            RCLCPP_INFO(this->get_logger(), 
                "Created service server: %s", "{{ srv.service }}");
                
        } catch (const std::exception& e) {
            RCLCPP_ERROR(this->get_logger(), 
                "Failed to create service {{ srv.service }}: %s", e.what());
            throw;
        }
    }
    {% endfor %}
    
    // Initialize action servers
    {% for action in actions %}
    {
        using namespace std::placeholders;
        
        try {
            auto handle_goal = [this](
                const rclcpp_action::GoalUUID& uuid,
                std::shared_ptr<const {{ action.action_type }}::Goal> goal
            ) -> rclcpp_action::GoalResponse {
                RCLCPP_INFO(this->get_logger(), 
                    "Received goal request for action {{ action.name }}");
                (void)uuid;
                (void)goal;
                return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE;
            };
            
            auto handle_cancel = [this](
                const std::shared_ptr<rclcpp_action::ServerGoalHandle<{{ action.action_type }}>> goal_handle
            ) -> rclcpp_action::CancelResponse {
                RCLCPP_INFO(this->get_logger(), 
                    "Received request to cancel goal for action {{ action.name }}");
                (void)goal_handle;
                return rclcpp_action::CancelResponse::ACCEPT;
            };
            
            auto handle_accepted = [this](
                const std::shared_ptr<rclcpp_action::ServerGoalHandle<{{ action.action_type }}>> goal_handle
            ) {
                std::thread{
                    std::bind(&{{ class_name }}::execute_{{ action.name }}, this, _1), 
                    goal_handle
                }.detach();
            };
            
            {{ action.name }}_action_server_ = rclcpp_action::create_server<{{ action.action_type }}>(
                this->get_node_base_interface(),
                this->get_node_clock_interface(),
                this->get_node_logging_interface(),
                this->get_node_waitables_interface(),
                "{{ action.topic }}",
                handle_goal,
                handle_cancel,
                handle_accepted
            );
            
            RCLCPP_INFO(this->get_logger(), 
                "Created action server: %s", "{{ action.topic }}");
                
        } catch (const std::exception& e) {
            RCLCPP_ERROR(this->get_logger(), 
                "Failed to create action server {{ action.name }}: %s", e.what());
            throw;
        }
    }
    {% endfor %}
}

{{ class_name }}::~{{ class_name }}()
{
    // Clean up CUDA resources if enabled
    {% if cuda_enabled %}
    #ifdef ENABLE_CUDA
    try {
        RCLCPP_DEBUG(this->get_logger(), "Releasing CUDA resources...");
        
        // Synchronize and destroy CUDA streams
        for (auto& [name, stream] : cuda_streams_) {
            if (stream) {
                cudaError_t status = cudaStreamSynchronize(stream);
                if (status != cudaSuccess) {
                    RCLCPP_ERROR(this->get_logger(), 
                        "Failed to synchronize CUDA stream '%s': %s", 
                        name.c_str(), cudaGetErrorString(status));
                }
                
                status = cudaStreamDestroy(stream);
                if (status != cudaSuccess) {
                    RCLCPP_ERROR(this->get_logger(), 
                        "Failed to destroy CUDA stream '%s': %s", 
                        name.c_str(), cudaGetErrorString(status));
                }
                
                stream = nullptr;
            }
        }
        cuda_streams_.clear();
        
        // Reset device to free all allocated resources
        cudaError_t status = cudaDeviceReset();
        if (status != cudaSuccess) {
            RCLCPP_ERROR(this->get_logger(), 
                "Failed to reset CUDA device: %s", cudaGetErrorString(status));
        }
        
        RCLCPP_DEBUG(this->get_logger(), "CUDA resources released successfully");
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(this->get_logger(), 
            "Error during CUDA cleanup: %s", e.what());
    }
    #endif
    {% endif %}
    
    // Cleanup CUDA resources if needed
    {% for kernel in cuda_kernels %}
    // Cleanup {{ kernel.name }} resources
    {% for member in kernel.members %}
    if ({{ member.name }}_) {
        cudaFree({{ member.name }}_);
        {{ member.name }}_ = nullptr;
    }
    {% endfor %}
    {% endfor %}
}

// Lifecycle callbacks
{{ 'rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn' if is_lifecycle else 'void' }}
{{ class_name }}::on_configure(const rclcpp_lifecycle::State& previous_state)
{
    {% if is_lifecycle %}
    RCLCPP_INFO(
        this->get_logger(), 
        "Configuring from [%s] state...", 
        previous_state.label().c_str()
    );
    
    try {
        // Load and validate parameters
        {% for param in parameters %}
        {
            rclcpp::Parameter param;
            if (this->get_parameter("{{ param.name }}", param)) {
                // Parameter loaded successfully
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Loaded parameter '%s': %s", 
                    "{{ param.name }}", 
                    param.value_to_string().c_str()
                );
                
                // Store the parameter value
                {{ param.name }}_ = param.template get<{{ param.type }}>();
            } else {
                RCLCPP_WARN(
                    this->get_logger(), 
                    "Failed to load parameter '%s', using default value", 
                    "{{ param.name }}"
                );
            }
        }
        {% endfor %}
        
        // Initialize any resources needed before activation
        {% if cuda_enabled %}
        #ifdef ENABLE_CUDA
        try {
            RCLCPP_DEBUG(this->get_logger(), "Initializing CUDA resources...");
            // Initialize CUDA streams
            for (auto& [name, stream] : cuda_streams_) {
                cudaError_t status = cudaStreamCreate(&stream);
                if (status != cudaSuccess) {
                    throw std::runtime_error(
                        std::string("Failed to create CUDA stream '") + name + "': " + 
                        cudaGetErrorString(status)
                    );
                }
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Created CUDA stream: %s", 
                    name.c_str()
                );
            }
        } catch (const std::exception& e) {
            RCLCPP_ERROR(
                this->get_logger(), 
                "CUDA initialization failed: %s", 
                e.what()
            );
            throw;
        }
        #endif
        {% endif %}
        
        RCLCPP_INFO(this->get_logger(), "Configuration completed successfully");
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::SUCCESS;
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Configuration failed: %s", 
            e.what()
        );
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::FAILURE;
    } catch (...) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Unknown error during configuration"
        );
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::ERROR;
    }
    {% else %}
    (void)previous_state;
    {% endif %}
}

{{ 'rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn' if is_lifecycle else 'void' }}
{{ class_name }}::on_activate(const rclcpp_lifecycle::State& previous_state)
{
    {% if is_lifecycle %}
    RCLCPP_INFO(
        this->get_logger(), 
        "Activating from [%s] state...", 
        previous_state.label().c_str()
    );
    
    try {
        // Activate publishers
        {% for pub in publishers %}
        if ({{ pub.name }}_pub_) {
            try {
                auto pub = std::dynamic_pointer_cast<rclcpp_lifecycle::LifecyclePublisher<{{ pub.msg_type }}>>({{ pub.name }}_pub_);
                if (pub) {
                    pub->on_activate();
                    RCLCPP_DEBUG(
                        this->get_logger(), 
                        "Activated publisher: %s", 
                        "{{ pub.topic }}"
                    );
                } else {
                    RCLCPP_WARN(
                        this->get_logger(), 
                        "Publisher '%s' is not a lifecycle publisher", 
                        "{{ pub.topic }}"
                    );
                }
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to activate publisher '%s': %s", 
                    "{{ pub.topic }}", 
                    e.what()
                );
                throw;
            }
        } else {
            RCLCPP_WARN(
                this->get_logger(), 
                "Publisher '%s' is null", 
                "{{ pub.topic }}"
            );
        }
        {% endfor %}
        
        // Start timers if they were running before deactivation
        {% for timer in timers %}
        if ({{ timer.name }}_was_active_) {
            try {
                {{ timer.name }}_timer_->reset();
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Restarted timer: %s", 
                    "{{ timer.name }}"
                );
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to restart timer '%s': %s", 
                    "{{ timer.name }}", 
                    e.what()
                );
                throw;
            }
        } else {
            RCLCPP_DEBUG(
                this->get_logger(), 
                "Skipping timer '%s' (was not active before deactivation)", 
                "{{ timer.name }}"
            );
        }
        {% endfor %}
        
        // Mark node as active
        is_active_ = true;
        
        RCLCPP_INFO(this->get_logger(), "Node activated successfully");
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::SUCCESS;
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Activation failed: %s", 
            e.what()
        );
        
        // Try to clean up partially activated resources
        try {
            on_deactivate(previous_state);
        } catch (...) {
            RCLCPP_ERROR(
                this->get_logger(), 
                "Error during cleanup after failed activation"
            );
        }
        
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::FAILURE;
    }
    {% else %}
    (void)previous_state;
    {% endif %}
}

{{ 'rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn' if is_lifecycle else 'void' }}
{{ class_name }}::on_deactivate(const rclcpp_lifecycle::State& previous_state)
{
    {% if is_lifecycle %}
    RCLCPP_INFO(
        this->get_logger(), 
        "Deactivating from [%s] state...", 
        previous_state.label().c_str()
    );
    
    try {
        // Mark node as inactive first to prevent new processing
        is_active_ = false;
        
        // Stop all timers and remember their state
        {% for timer in timers %}
        if ({{ timer.name }}_timer_) {
            try {
                {{ timer.name }}_was_active_ = !{{ timer.name }}_timer_->is_canceled();
                if ({{ timer.name }}_was_active_) {
                    {{ timer.name }}_timer_->cancel();
                    RCLCPP_DEBUG(
                        this->get_logger(), 
                        "Stopped timer: %s", 
                        "{{ timer.name }}"
                    );
                } else {
                    RCLCPP_DEBUG(
                        this->get_logger(), 
                        "Timer '%s' was already stopped", 
                        "{{ timer.name }}"
                    );
                }
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to stop timer '%s': %s", 
                    "{{ timer.name }}", 
                    e.what()
                );
                throw;
            }
        } else {
            RCLCPP_WARN(
                this->get_logger(), 
                "Timer '%s' is null", 
                "{{ timer.name }}"
            );
        }
        {% endfor %}
        
        // Deactivate publishers
        {% for pub in publishers %}
        if ({{ pub.name }}_pub_) {
            try {
                auto pub = std::dynamic_pointer_cast<rclcpp_lifecycle::LifecyclePublisher<{{ pub.msg_type }}>>({{ pub.name }}_pub_);
                if (pub) {
                    if (pub->is_activated()) {
                        pub->on_deactivate();
                        RCLCPP_DEBUG(
                            this->get_logger(), 
                            "Deactivated publisher: %s", 
                            "{{ pub.topic }}"
                        );
                    } else {
                        RCLCPP_DEBUG(
                            this->get_logger(), 
                            "Publisher '%s' was not active", 
                            "{{ pub.topic }}"
                        );
                    }
                } else {
                    RCLCPP_WARN(
                        this->get_logger(), 
                        "Publisher '%s' is not a lifecycle publisher", 
                        "{{ pub.topic }}"
                    );
                }
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to deactivate publisher '%s': %s", 
                    "{{ pub.topic }}", 
                    e.what()
                );
                throw;
            }
        } else {
            RCLCPP_WARN(
                this->get_logger(), 
                "Publisher '%s' is null", 
                "{{ pub.topic }}"
            );
        }
        {% endfor %}
        
        RCLCPP_INFO(this->get_logger(), "Node deactivated successfully");
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::SUCCESS;
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Deactivation failed: %s", 
            e.what()
        );
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::FAILURE;
    }
    {% else %}
    (void)previous_state;
    {% endif %}
}

{{ 'rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn' if is_lifecycle else 'void' }}
{{ class_name }}::on_cleanup(const rclcpp_lifecycle::State& previous_state)
{
    {% if is_lifecycle %}
    RCLCPP_INFO(
        this->get_logger(), 
        "Cleaning up from [%s] state...", 
        previous_state.label().c_str()
    );
    
    try {
        // Reset timers
        {% for timer in timers %}
        if ({{ timer.name }}_timer_) {
            try {
                {{ timer.name }}_timer_->cancel();
                {{ timer.name }}_timer_.reset();
                {{ timer.name }}_was_active_ = false;
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Reset timer: %s", 
                    "{{ timer.name }}"
                );
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to reset timer '%s': %s", 
                    "{{ timer.name }}", 
                    e.what()
                );
                throw;
            }
        }
        {% endfor %}
        
        // Reset publishers
        {% for pub in publishers %}
        if ({{ pub.name }}_pub_) {
            try {
                {{ pub.name }}_pub_.reset();
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Reset publisher: %s", 
                    "{{ pub.topic }}"
                );
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to reset publisher '%s': %s", 
                    "{{ pub.topic }}", 
                    e.what()
                );
                throw;
            }
        }
        {% endfor %}
        
        // Reset subscribers
        {% for sub in subscribers %}
        if ({{ sub.name }}_sub_) {
            try {
                {{ sub.name }}_sub_.reset();
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Reset subscriber: %s", 
                    "{{ sub.topic }}"
                );
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to reset subscriber '%s': %s", 
                    "{{ sub.topic }}", 
                    e.what()
                );
                throw;
            }
        }
        {% endfor %}
        
        // Reset services
        {% for srv in services %}
        if ({{ srv.name }}_srv_) {
            try {
                {{ srv.name }}_srv_.reset();
                RCLCPP_DEBUG(
                    this->get_logger(), 
                    "Reset service: %s", 
                    "{{ srv.service }}"
                );
            } catch (const std::exception& e) {
                RCLCPP_ERROR(
                    this->get_logger(), 
                    "Failed to reset service '%s': %s", 
                    "{{ srv.service }}", 
                    e.what()
                );
                throw;
            }
        }
        {% endfor %}
        
        // Clean up CUDA resources if enabled
        {% if cuda_enabled %}
        #ifdef ENABLE_CUDA
        try {
            RCLCPP_DEBUG(this->get_logger(), "Cleaning up CUDA resources...");
            
            // Synchronize and destroy CUDA streams
            for (auto& [name, stream] : cuda_streams_) {
                if (stream) {
                    cudaError_t status = cudaStreamSynchronize(stream);
                    if (status != cudaSuccess) {
                        RCLCPP_WARN(
                            this->get_logger(), 
                            "Failed to synchronize CUDA stream '%s': %s", 
                            name.c_str(), 
                            cudaGetErrorString(status)
                        );
                    }
                    
                    status = cudaStreamDestroy(stream);
                    if (status != cudaSuccess) {
                        RCLCPP_WARN(
                            this->get_logger(), 
                            "Failed to destroy CUDA stream '%s': %s", 
                            name.c_str(), 
                            cudaGetErrorString(status)
                        );
                    }
                    
                    stream = nullptr;
                }
            }
            cuda_streams_.clear();
            
            RCLCPP_DEBUG(this->get_logger(), "CUDA resources cleaned up");
            
        } catch (const std::exception& e) {
            RCLCPP_WARN(
                this->get_logger(), 
                "Error during CUDA cleanup: %s", 
                e.what()
            );
            // Don't rethrow to allow cleanup to continue
        }
        #endif
        {% endif %}
        
        RCLCPP_INFO(this->get_logger(), "Node cleanup completed successfully");
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::SUCCESS;
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Cleanup failed: %s", 
            e.what()
        );
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::ERROR;
    }
    {% else %}
    (void)previous_state;
    {% endif %}
}

{{ 'rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn' if is_lifecycle else 'void' }}
{{ class_name }}::on_shutdown(const rclcpp_lifecycle::State& previous_state)
{
    {% if is_lifecycle %}
    RCLCPP_INFO(
        this->get_logger(), 
        "Shutting down from [%s] state...", 
        previous_state.label().c_str()
    );
    
    try {
        // Call cleanup first to ensure all resources are released
        on_cleanup(previous_state);
        
        // Additional shutdown-specific cleanup
        {% if cuda_enabled %}
        #ifdef ENABLE_CUDA
        try {
            RCLCPP_DEBUG(this->get_logger(), "Resetting CUDA device...");
            cudaError_t status = cudaDeviceReset();
            if (status != cudaSuccess) {
                RCLCPP_WARN(
                    this->get_logger(), 
                    "Failed to reset CUDA device: %s", 
                    cudaGetErrorString(status)
                );
            } else {
                RCLCPP_DEBUG(this->get_logger(), "CUDA device reset successfully");
            }
        } catch (const std::exception& e) {
            RCLCPP_WARN(
                this->get_logger(), 
                "Error during CUDA device reset: %s", 
                e.what()
            );
            // Don't rethrow to allow shutdown to complete
        }
        #endif
        {% endif %}
        
        RCLCPP_INFO(this->get_logger(), "Node shutdown completed successfully");
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::SUCCESS;
        
    } catch (const std::exception& e) {
        RCLCPP_ERROR(
            this->get_logger(), 
            "Shutdown failed: %s", 
            e.what()
        );
        return rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn::ERROR;
    }
    {% else %}
    (void)previous_state;
    {% endif %}
}

// Timer callbacks
{% for timer in timers %}
void {{ class_name }}::{{ timer.callback_name }}()
{
    // Timer callback implementation
    RCLCPP_DEBUG(this->get_logger(), "Timer {{ timer.name }} triggered");
}

{% endfor %}

// Subscriber callbacks
{% for sub in subscribers %}
void {{ class_name }}::{{ sub.callback_name }}(const {{ sub.msg_type }}::ConstSharedPtr msg)
{
    // Process message
    RCLCPP_DEBUG(this->get_logger(), "Received message on {{ sub.topic }}");
}

{% endfor %}

// Service callbacks
{% for srv in services %}
void {{ class_name }}::{{ srv.callback_name }}(
    const std::shared_ptr<{{ srv.srv_type }}::Request> request,
    std::shared_ptr<{{ srv.srv_type }}::Response> response)
{
    // Process service request
    RCLCPP_DEBUG(this->get_logger(), "Service {{ srv.service }} called");
}

{% endfor %}

// CUDA methods
{% if cuda_kernels %}
bool {{ class_name }}::initializeCuda() {
    RCLCPP_DEBUG(this->get_logger(), "Initializing CUDA resources");
    try {
        // Initialize CUDA device
        cudaError_t status = cudaSetDevice(cuda_device_id_);
        if (status != cudaSuccess) {
            RCLCPP_ERROR(this->get_logger(), 
                       "Failed to set CUDA device %d: %s", 
                       cuda_device_id_, 
                       cudaGetErrorString(status));
            return false;
        }
        
        // Get and log device properties
        cudaDeviceProp props;
        status = cudaGetDeviceProperties(&props, cuda_device_id_);
        if (status == cudaSuccess) {
            RCLCPP_INFO(this->get_logger(), 
                      "Using CUDA device %d: %s (Compute %d.%d)",
                      cuda_device_id_, 
                      props.name, 
                      props.major, 
                      props.minor);
        }
        
        return true;
    } catch (const std::exception& e) {
        RCLCPP_ERROR(this->get_logger(), 
                   "Exception during CUDA initialization: %s", 
                   e.what());
        return false;
    } catch (...) {
        RCLCPP_ERROR(this->get_logger(), 
                   "Unknown exception during CUDA initialization");
        return false;
    }
}

void {{ class_name }}::cleanupCuda() {
    RCLCPP_DEBUG(this->get_logger(), "Cleaning up CUDA resources");
    try {
        // Synchronize and reset the device
        cudaDeviceSynchronize();
        cudaDeviceReset();
    } catch (const std::exception& e) {
        RCLCPP_ERROR(this->get_logger(), 
                   "Exception during CUDA cleanup: %s", 
                   e.what());
    } catch (...) {
        RCLCPP_ERROR(this->get_logger(), 
                   "Unknown exception during CUDA cleanup");
    }
}

std::vector<{{ cuda_default_output_type|default('float') }}> 
{{ class_name }}::processWithCuda(
    const std::vector<{{ cuda_default_input_type|default('float') }}>& input,
    const {{ cuda_default_param_type|default('CudaParams') }}& parameters) 
{
    RCLCPP_DEBUG(this->get_logger(), "Default processWithCuda implementation called");
    // Default implementation returns an empty vector
    // Override this method in derived classes to provide actual CUDA processing
    return {};
}

// CUDA kernel wrappers
{% for kernel in cuda_kernels %}
std::vector<{{ kernel.output_type|default('float') }}> 
{{ class_name }}::{{ kernel.name }}(
    const std::vector<{{ kernel.input_type|default('float') }}>& input,
    const {{ kernel.param_type|default('CudaParams') }}& parameters)
{
    RCLCPP_DEBUG(this->get_logger(), "CUDA kernel {{ kernel.name }} called with %zu elements", input.size());
    
    // Default implementation returns an empty vector
    // Override this method in derived classes to provide actual CUDA kernel execution
    return std::vector<{{ kernel.output_type|default('float') }}>();
}

{% endfor %}
{% endif %}

{% if cpp_helpers %}
// User-defined C++ helper code blocks
{% for h in cpp_helpers %}
{{ h }}
{% endfor %}
{% endif %}

{% if methods %}
// User-defined C++ method implementations
{% for m in methods %}
{{ m.return_type }} {{ class_name }}::{{ m.name }}({{ m.params }})
{
    {{ m.body | default('// TODO: implement') }}
}

{% endfor %}
{% endif %}

{% if namespace %}
} // namespace {{ namespace }}
{% endif %}
