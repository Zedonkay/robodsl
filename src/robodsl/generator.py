"""
Code generation for RoboDSL.

This module handles the generation of C++ and CUDA source files from the parsed DSL configuration.
"""

import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from .parser import RoboDSLConfig, NodeConfig, CudaKernelConfig


@dataclass
class CodeGenerator:
    """Generates C++ and CUDA source code from RoboDSL configuration."""
    
    def __init__(self, config: RoboDSLConfig, output_dir: str = "."):
        """Initialize the code generator with the parsed DSL configuration.
        
        Args:
            config: The parsed RoboDSL configuration
            output_dir: Base directory for generated files (default: current directory)
        """
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate(self) -> None:
        """Generate all source files from the DSL configuration."""
        # Create output directories
        (self.output_dir / 'include' / 'robodsl').mkdir(parents=True, exist_ok=True)
        (self.output_dir / 'src').mkdir(exist_ok=True)
        
        # Generate node headers and source files
        for node in self.config.nodes:
            self._generate_node_header(node)
            self._generate_node_source(node)
        
        # Generate CUDA kernel files
        for kernel in self.config.cuda_kernels:
            self._generate_cuda_kernel(kernel)
        
        # Generate CMake configuration
        self._generate_cmakelists()
    
    def _generate_node_header(self, node: NodeConfig) -> None:
        """Generate a C++ header file for a ROS2 node.
        
        Args:
            node: The node configuration
        """
        # Convert node name to a valid C++ class name (e.g., 'my_node' -> 'MyNode')
        class_name = ''.join(word.capitalize() for word in node.name.split('_'))
        header_guard = f"{node.name.upper()}_NODE_HPP_"
        
        # Generate includes based on message types used
        includes = [
            '#include "rclcpp/rclcpp.hpp"',
            '#include <memory>',
            '#include <string>',
            '#include <map>',
            '',  # For better formatting
        ]
        
        # Add message includes for publishers and subscribers
        msg_includes = set()
        for pub in node.publishers:
            msg_includes.add(f'#include "{pub["msg_type"].replace(".", "/")}.hpp"')
        for sub in node.subscribers:
            msg_includes.add(f'#include "{sub["msg_type"].replace(".", "/")}.hpp"')
        
        # Add service includes
        for srv in node.services:
            msg_includes.add(f'#include "{srv["srv_type"].replace(".", "/")}.hpp"')
        
        # Sort includes for consistent output
        includes.extend(sorted(msg_includes))
        
        # Generate the class declaration parts
        ros_publishers = self._generate_publisher_declarations(node.publishers)
        ros_subscribers = self._generate_subscriber_declarations(node.subscribers)
        ros_services = self._generate_service_declarations(node.services)
        parameters = self._generate_parameter_declarations(node.parameters)
        cuda_kernels = self._generate_cuda_kernel_declarations(node.name, self.config.cuda_kernels)
        
        # Generate class declaration using f-strings to avoid format() conflicts
        class_declaration = f"""class {class_name} : public rclcpp::Node {{
public:
    {class_name}();
    virtual ~{class_name}();

private:
    // ROS2 Publishers
{ros_publishers}
    
    // ROS2 Subscribers
{ros_subscribers}
    
    // ROS2 Services
{ros_services}
    
    // Parameters
{parameters}

    // CUDA Kernels
{cuda_kernels}
}};
"""
        
        # Write the header file
        header_content = f"""// Generated by RoboDSL - DO NOT EDIT

#ifndef {header_guard}
#define {header_guard}

{"\n".join(includes)}

namespace robodsl {{

{class_declaration}

}}  // namespace robodsl

#endif  // {header_guard}
"""
        
        # Create output directory if it doesn't exist
        header_path = self.output_dir / 'include' / 'robodsl' / f"{node.name}_node.hpp"
        header_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(header_path, 'w') as f:
            f.write(header_content)
    
    def _generate_publisher_declarations(self, publishers: List[Dict[str, str]]) -> str:
        """Generate C++ declarations for ROS2 publishers."""
        if not publishers:
            return '    // No publishers declared\n'
            
        result = []
        for pub in publishers:
            # Convert message type to C++ type (e.g., 'std_msgs/msg/String' -> 'std_msgs::msg::String')
            msg_type = pub['msg_type'].replace('/', '::')
            var_name = f"{pub['topic'].lstrip('/').replace('/', '_')}_pub_"
            result.append(f'    rclcpp::Publisher<{msg_type}>::SharedPtr {var_name};')
        
        return '\n'.join(result) + '\n'
    
    def _generate_subscriber_declarations(self, subscribers: List[Dict[str, str]]) -> str:
        """Generate C++ declarations for ROS2 subscribers."""
        if not subscribers:
            return '    // No subscribers declared\n'
            
        result = []
        for sub in subscribers:
            # Convert message type to C++ type
            msg_type = sub['msg_type'].replace('/', '::')
            var_name = f"{sub['topic'].lstrip('/').replace('/', '_')}_sub_"
            callback_name = f"{sub['topic'].lstrip('/').replace('/', '_')}_callback"
            result.append(f'    rclcpp::Subscription<{msg_type}>::SharedPtr {var_name};')
            result.append(f'    void {callback_name}(const {msg_type}::SharedPtr msg) const;')
        
        return '\n'.join(result) + '\n'
    
    def _generate_service_declarations(self, services: List[Dict[str, str]]) -> str:
        """Generate C++ declarations for ROS2 services."""
        if not services:
            return '    // No services declared\n'
            
        result = []
        for srv in services:
            # Convert service type to C++ type
            srv_type = srv['srv_type'].replace('/', '::')
            var_name = f"{srv['service'].lstrip('/').replace('/', '_')}_srv_"
            callback_name = f"{srv['service'].lstrip('/').replace('/', '_')}_callback"
            result.append(f'    rclcpp::Service<{srv_type}>::SharedPtr {var_name};')
            result.append(f'    void {callback_name}(')
            result.append(f'        const std::shared_ptr<{srv_type}::Request> request,')
            result.append(f'        std::shared_ptr<{srv_type}::Response> response);')
        
        return '\n'.join(result) + '\n'
    
    def _generate_parameter_declarations(self, parameters: Dict[str, str]) -> str:
        """Generate C++ declarations for node parameters."""
        if not parameters:
            return '    // No parameters declared\n'
            
        result = ['    // Parameters']
        for name, value in parameters.items():
            # Determine parameter type from value
            if value.lower() in ('true', 'false'):
                param_type = 'bool'
            elif value.replace('.', '', 1).isdigit():
                param_type = 'double' if '.' in value else 'int'
            else:
                param_type = 'std::string'
            
            result.append(f'    {param_type} {name}_;')
        
        return '\n'.join(result) + '\n'
    
    def _generate_cuda_kernel_declarations(self, node_name: str, kernels: List[CudaKernelConfig]) -> str:
        """Generate C++ declarations for CUDA kernels used by this node."""
        node_kernels = [k for k in kernels if k.name.startswith(node_name)]
        
        if not node_kernels:
            return '    // No CUDA kernels for this node\n'
            
        result = ['    // CUDA Kernels']
        for kernel in node_kernels:
            # Generate a C++ class for the CUDA kernel
            class_name = f"{kernel.name.capitalize()}Kernel"
            result.extend([
                f'    class {class_name} {{',
                '    public:',
                f'        {class_name}();',
                '        ~CudaKernel();',
                '        void configure(const std::map<std::string, std::string>& params);',
                '        void cleanup();',
                '        void process();',
                '    private:',
                '        // Kernel-specific data members',
                '    };',
                ''
            ])
        
        return '\n'.join(result)
    
    def _generate_cuda_kernel(self, kernel: CudaKernelConfig) -> None:
        """Generate CUDA kernel implementation files.
        
        Args:
            kernel: The CUDA kernel configuration
        """
        # Create output directories if they don't exist
        cuda_include_dir = self.output_dir / 'include' / 'robodsl' / 'cuda'
        cuda_src_dir = self.output_dir / 'src' / 'cuda'
        cuda_include_dir.mkdir(parents=True, exist_ok=True)
        cuda_src_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate CUDA header file (.cuh)
        self._generate_cuda_header(kernel, cuda_include_dir)
        
        # Generate CUDA source file (.cu)
        self._generate_cuda_source(kernel, cuda_src_dir)
    
    def _generate_cuda_header(self, kernel: CudaKernelConfig, output_dir: Path) -> None:
        """Generate CUDA kernel header file.
        
        Args:
            kernel: The CUDA kernel configuration
            output_dir: Directory to write the header file to
        """
        class_name = f"{kernel.name.capitalize()}Kernel"
        header_guard = f"{kernel.name.upper()}_KERNEL_H_"
        
        # Generate input/output parameter declarations
        input_params = []
        output_params = []
        
        for i, input_def in enumerate(kernel.inputs):
            param_name = f"input_{i}"
            input_params.append(f"const {input_def['type']}& {param_name}")
        
        for i, output_def in enumerate(kernel.outputs):
            param_name = f"output_{i}"
            output_params.append(f"{output_def['type']}& {param_name}")
        
        # Generate function declaration
        function_decl = f"void {kernel.name}("
        function_decl += ", ".join(input_params + output_params)
        function_decl += ");"
        
        # Generate header content
        header_content = f"""// Generated by RoboDSL - DO NOT EDIT

#ifndef {header_guard}
#define {header_guard}

#include <cuda_runtime.h>

class {class_name} {{
public:
    {class_name}();
    ~{class_name}();
    
    // Configure kernel with parameters
    void configure(const std::map<std::string, std::string>& params);
    
    // Process data using CUDA kernel
    {function_decl}
    
private:
    // Kernel-specific configuration
    dim3 block_size_;
    dim3 grid_size_;
    
    // Add any CUDA device pointers or other state here
}};

#endif // {header_guard}
"""
        
        # Write header file
        header_path = output_dir / f"{kernel.name}_kernel.cuh"
        with open(header_path, 'w') as f:
            f.write(header_content)
    
    def _generate_cuda_source(self, kernel: CudaKernelConfig, output_dir: Path) -> None:
        """Generate CUDA kernel source file.
        
        Args:
            kernel: The CUDA kernel configuration
            output_dir: Directory to write the source file to
        """
        class_name = f"{kernel.name.capitalize()}Kernel"
        
        # Get block size with defaults
        block_x = kernel.block_size[0] if hasattr(kernel, 'block_size') and len(kernel.block_size) > 0 else 16
        block_y = kernel.block_size[1] if hasattr(kernel, 'block_size') and len(kernel.block_size) > 1 else 1
        block_z = kernel.block_size[2] if hasattr(kernel, 'block_size') and len(kernel.block_size) > 2 else 1
        
        # Generate CUDA kernel function
        kernel_function_parts = ["// CUDA kernel function"]
        kernel_function_parts.append(f"__global__ void {kernel.name}Kernel(")
        
        # Add input parameters
        params = []
        for i, input_def in enumerate(kernel.inputs):
            params.append(f"const {input_def['type']}* input_{i}")
        
        # Add output parameters
        for i, output_def in enumerate(kernel.outputs):
            params.append(f"{output_def['type']}* output_{i}")
        
        kernel_function_parts.append(", ".join(params) + ") {")
        kernel_function_parts.append("    // TODO: Implement kernel logic here")
        kernel_function_parts.append("    // Example: output[threadIdx.x] = input[threadIdx.x];")
        kernel_function_parts.append("}")
        kernel_function = "\n".join(kernel_function_parts)
        
        # Generate class method implementations
        class_impl_parts = [
            f"// Constructor",
            f"{class_name}::{class_name}() {{",
            f"    // Default block size from kernel config or use a default",
            f"    block_size_ = dim3({block_x}, {block_y}, {block_z});",
            f"    // Grid size will be calculated based on input dimensions",
            f"}}",
            "",
            f"// Destructor",
            f"{class_name}::~{class_name}() {{",
            f"    // Cleanup any allocated resources",
            f"}}",
            "",
            f"// Configure kernel with parameters",
            f"void {class_name}::configure(const std::map<std::string, std::string>& params) {{",
            f"    // TODO: Parse and apply configuration parameters",
            f"    // Example: block_size_.x = std::stoi(params.at(\"block_size_x\"));",
            f"}}",
            "",
            f"// Process data using CUDA kernel",
            f"void {class_name}::{kernel.name}("
        ]
        
        # Add method parameters
        method_params = []
        for i, input_def in enumerate(kernel.inputs):
            method_params.append(f"const {input_def['type']}& input_{i}")
        
        for i, output_def in enumerate(kernel.outputs):
            method_params.append(f"{output_def['type']}& output_{i}")
        
        class_impl_parts.append(", ".join(method_params) + ") {")
        
        # Add method implementation
        class_impl_parts.extend([
            "    // Calculate grid size based on input dimensions",
            "    // TODO: Implement proper grid size calculation based on input dimensions",
            "    grid_size_ = dim3(1, 1, 1);",
            "",
            "    // Launch kernel",
            f"    {kernel.name}Kernel<<<grid_size_, block_size_>>>("
        ])
        
        # Add kernel arguments
        kernel_args = []
        for i in range(len(kernel.inputs)):
            kernel_args.append(f"input_{i}.data()")
            
        for i in range(len(kernel.outputs)):
            kernel_args.append(f"output_{i}.data()")
        
        class_impl_parts.append("        " + ", ".join(kernel_args) + ");")
        
        # Add error checking
        class_impl_parts.extend([
            "",
            "    // Check for kernel launch errors",
            "    cudaError_t err = cudaGetLastError();",
            "    if (err != cudaSuccess) {",
            "        // TODO: Better error handling",
            "        throw std::runtime_error(cudaGetErrorString(err));",
            "    }",
            "",
            "    // Synchronize to check for kernel execution errors",
            "    err = cudaDeviceSynchronize();",
            "    if (err != cudaSuccess) {",
            "        throw std::runtime_error(cudaGetErrorString(err));",
            "    }",
            "}"
        ])
        
        class_impl = "\n".join(class_impl_parts)
        
        # Format the source content
        source_content = f"""// Generated by RoboDSL - DO NOT EDIT

#include "robodsl/cuda/{kernel.name}_kernel.cuh"
#include <stdexcept>
#include <string>

// Kernel parameters
constexpr int BLOCK_SIZE_X = {block_x};
constexpr int BLOCK_SIZE_Y = {block_y};
constexpr int BLOCK_SIZE_Z = {block_z};

{kernel_function}

{class_impl}
"""
        
        # Write source file
        source_path = output_dir / f"{kernel.name}_kernel.cu"
        with open(source_path, 'w') as f:
            f.write(source_content)
    
    def _generate_cmakelists(self) -> None:
        """Generate CMakeLists.txt for the project."""
        cmake_path = self.output_dir / 'CMakeLists.txt'
        
        # Get all node names
        node_names = [node.name for node in self.config.nodes]
        
        # Get all CUDA kernel names
        cuda_kernel_names = [kernel.name for kernel in self.config.cuda_kernels]
        
        # Generate CMake content - using double $$ to escape CMake variables
        cmake_content = f"""# Generated by RoboDSL - DO NOT EDIT
cmake_minimum_required(VERSION 3.8)
project({self.config.project_name})

# Default to C++17
if(NOT CMAKE_CXX_STANDARD)
  set(CMAKE_CXX_STANDARD 17)
  set(CMAKE_CXX_STANDARD_REQUIRED ON)
  set(CMAKE_CXX_EXTENSIONS OFF)
endif()

# Find dependencies
find_package(ament_cmake REQUIRED)
find_package(rclcpp REQUIRED)
find_package(std_msgs REQUIRED)

# Find CUDA
find_package(CUDA REQUIRED)

# Set include directories
include_directories(
  include
  ${{CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}}
  ${{CMAKE_CURRENT_BINARY_DIR}}
)

# Set compile definitions
add_compile_definitions(ROS_DISTRO_${{ROS_DISTRO}})

# Set compile options
if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES "Clang")
  add_compile_options(-Wall -Wextra -Wpedantic)
endif()

# Add CUDA include directory
include_directories(${{CUDA_INCLUDE_DIRS}})

# Add CUDA flags
set(CUDA_NVCC_FLAGS "${{CUDA_NVCC_FLAGS}} -std=c++17 -O2 -Xcompiler -fPIC")

# Find all source files
file(GLOB_RECURSE NODE_SRCS
  "src/*.cpp"
)

# Find all CUDA source files
file(GLOB_RECURSE CUDA_SRCS
  "src/cuda/*.cu"
)

# Create a list of all CUDA kernels to compile
set(CUDA_KERNEL_TARGETS "")
"""

        # Add CUDA kernel compilation rules
        for kernel in self.config.cuda_kernels:
            cmake_content += f"""
# CUDA kernel: {kernel.name}
cuda_add_library({kernel.name}_kernel
  src/cuda/{kernel.name}_kernel.cu
)
target_link_libraries({kernel.name}_kernel
  ${{CUDA_LIBRARIES}}
  ${{CUDA_CUDA_LIBRARY}}
)
target_include_directories({kernel.name}_kernel
  PUBLIC
    ${{CMAKE_CURRENT_SOURCE_DIR}}/include
)
set_target_properties({kernel.name}_kernel PROPERTIES
  CUDA_SEPARABLE_COMPILATION ON
  POSITION_INDEPENDENT_CODE ON
)
list(APPEND CUDA_KERNEL_TARGETS {kernel.name}_kernel)
"""

        # Add node compilation rules
        cmake_content += """
# Create node libraries
"""
        for node in self.config.nodes:
            cmake_name = node.name.replace('-', '_')
            cmake_content += f"""
# Node: {node.name}
add_library({cmake_name}_node
  src/{node.name}_node.cpp
)
target_link_libraries({cmake_name}_node
  ${{rclcpp_LIBRARIES}}
  "$<BUILD_INTERFACE:${{CMAKE_CURRENT_SOURCE_DIR}}/include>"
  "$<INSTALL_INTERFACE:include>"
)
"""
            
            # Link CUDA kernels if any
            if self.config.cuda_kernels:
                cmake_content += "  # Link CUDA kernels\n"
                for kernel in self.config.cuda_kernels:
                    cmake_content += f"  {kernel.name}_kernel\n"
                cmake_content += "\n"
            
            # Add executable
            cmake_content += f"""add_executable({cmake_name}_node_exe
  src/{node.name}_node_main.cpp
)
target_link_libraries({cmake_name}_node_exe
  {cmake_name}_node
  ${{rclcpp_LIBRARIES}}
)
"""

        # Add installation rules
        cmake_content += """
# Install rules
install(TARGETS
  ${CUDA_KERNEL_TARGETS}
  ARCHIVE DESTINATION lib
  LIBRARY DESTINATION lib
  RUNTIME DESTINATION bin
)

install(DIRECTORY
  include/
  DESTINATION include/
)

# Install node executables
"""
        for node in self.config.nodes:
            cmake_name = node.name.replace('-', '_')
            cmake_content += f"""install(TARGETS
  {cmake_name}_node {cmake_name}_node_exe
  DESTINATION lib/${{PROJECT_NAME}}
)
"""

        # Add ament exports
        cmake_content += """
# Ament exports
ament_export_include_directories(include)
ament_export_libraries(${CUDA_KERNEL_TARGETS})

# Add ament package
ament_package()
"""
        # Write CMakeLists.txt
        with open(cmake_path, 'w') as f:
            f.write(cmake_content)
