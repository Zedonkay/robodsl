// Generated by RoboDSL - DO NOT EDIT


#ifndef TRAJECTORY_PLANNING_KERNEL_HPP
#define TRAJECTORY_PLANNING_KERNEL_HPP



#include <cuda_runtime.h>
#include <cstdint>
#include <string>

// Define uchar type if not already defined
#ifndef __UCHAR_TYPE__
typedef unsigned char uchar;
#endif



namespace robodsl {


/**
 * @brief CUDA kernel wrapper class for trajectory_planning
 * 
 * This class provides a C++ interface to CUDA kernels, handling memory management
 * and kernel launches. It's designed to work with the ROS2 node lifecycle.
 */
class trajectory_planningKernel {
public:
    /**
     * @brief Construct a new trajectory_planning Kernel object
     * 
     * @param stream CUDA stream to use for kernel execution (nullptr for default stream)
     */
    explicit trajectory_planningKernel(cudaStream_t* stream = nullptr);
    
    /**
     * @brief Destroy the trajectory_planning Kernel object
     * 
     * Frees all allocated device memory.
     */
    ~trajectory_planningKernel();
    
    // Delete copy constructor and assignment operator
    trajectory_planningKernel(const trajectory_planningKernel&) = delete;
    trajectory_planningKernel& operator=(const trajectory_planningKernel&) = delete;
    
    /**
     * @brief Initialize the kernel with input data
     * 
     * @param input Input data to process
     * @return true if initialization was successful, false otherwise
     */
    // Initialize the kernel with input data (host pointer and size)
    bool initialize(const float** input, size_t input_size);
    
    /**
     * @brief Process the input data using the CUDA kernel
     * 
     * @param parameters Kernel parameters
     * @return std::vector<float*> Processed output data
     */
    // Process the input data using the CUDA kernel (host pointer and size)
    bool process(const int** parameters, size_t param_size, float** output, size_t output_size);
    
    /**
     * @brief Get the last error message, if any
     * 
     * @return std::string The last error message, or an empty string if no error
     */
    const std::string& getLastError() const { return last_error_; }
    
    /**
     * @brief Check if the kernel was initialized successfully
     * 
     * @return true if initialized, false otherwise
     */
    bool isInitialized() const { return initialized_; }
    
private:
    // Device memory pointers
    float** d_current_pose_ = nullptr;  //!< Device memory for current_pose
    float** d_target_pose_ = nullptr;  //!< Device memory for target_pose
    float** d_obstacles_ = nullptr;  //!< Device memory for obstacles
    int* d_num_obstacles_ = nullptr;  //!< Device memory for num_obstacles
    float** d_planned_trajectory_ = nullptr;  //!< Device memory for planned_trajectory
    int** d_trajectory_length_ = nullptr;  //!< Device memory for trajectory_length

    // Kernel state and configuration
    size_t input_size_ = 0;                //!< Number of input elements
    int device_id_ = 0;                    //!< CUDA device ID
    int max_threads_per_block_ = 256;      //!< Max threads per block
    int max_blocks_per_dim_ = 65535;       //!< Max blocks per grid dimension


    // Parameter state (for kernels with parameters)
    bool parameters_copied_ = false;
    int* last_parameters_{};
    int** d_parameters_ = nullptr;

    cudaStream_t* stream_ = nullptr;  //!< CUDA stream for async operations
    bool initialized_ = false;        //!< Whether the kernel is properly initialized
    std::string last_error_;         //!< Last error message, if any
    
    // CUDA kernel launch configuration
    static constexpr int kBlockSize = 256;  //!< Threads per block
    
    /**
     * @brief Check for CUDA errors and update last_error_ if needed
     * 
     * @param status CUDA status to check
     * @param context Context string for error messages
     * @return true if no error, false otherwise
     */
    bool checkCudaError(cudaError_t status, const std::string& context);
    
    /**
     * @brief Allocate device memory
     * 
     * @return true if allocation was successful, false otherwise
     */
    bool allocateDeviceMemory();
    
    /**
     * @brief Free device memory
     */
    void freeDeviceMemory();
};

// Kernel function declaration (must be a free function, not a member function)
__global__ void trajectory_planning_kernel(    const float** d_current_pose_,    const float** d_target_pose_,    const float** d_obstacles_,    const int* d_num_obstacles_,    const float** d_planned_trajectory_,    const int** d_trajectory_length_,    int num_elements
);

} // namespace robodsl


#endif // TRAJECTORY_PLANNING_KERNEL_HPP
