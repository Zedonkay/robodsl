// Generated by RoboDSL - DO NOT EDIT

#ifndef PATH_PLANNING_ASTAR_KERNEL_HPP
#define PATH_PLANNING_ASTAR_KERNEL_HPP

// Standard includes
#include <memory>
#include <vector>
#include <string>
#include <functional>
#include <chrono>
#include <map>
#include <algorithm>

// CUDA includes
#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <thrust/device_vector.h>
#include <thrust/host_vector.h>

// ROS2 includes
#include <rclcpp/rclcpp.hpp>
#include <std_msgs/msg/float32_multi_array.hpp>
#include <sensor_msgs/msg/image.hpp>

// CUDA kernel header
#include "cuda/path_planning_astar_kernel.cuh"

namespace robodsl {

/**
 * @brief ROS2-compatible CUDA kernel wrapper for path_planning_astar
 * 
 * This class provides a high-level interface for using CUDA kernels in ROS2 nodes.
 * It handles memory management, error checking, and provides convenient methods
 * for processing ROS2 messages.
 */
class path_planning_astarWrapper {
public:
    /**
     * @brief Construct a new path_planning_astar Wrapper object
     * 
     * @param node ROS2 node for logging and parameter access
     * @param stream CUDA stream for asynchronous operations (nullptr for default)
     */
    explicit path_planning_astarWrapper(
        rclcpp::Node* node = nullptr,
        cudaStream_t stream = nullptr
    ) : node_(node), stream_(stream), device_id_(0), initialized_(false), allocated_size_(0) {
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), "Creating path_planning_astarWrapper");
        }
    }
    
    /**
     * @brief Destroy the path_planning_astar Wrapper object
     * 
     * Frees all allocated device memory and CUDA resources.
     */
    ~path_planning_astarWrapper() {
        freeDeviceMemory();
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), "Destroying path_planning_astarWrapper");
        }
    }
    
    // Delete copy constructor and assignment operator
    path_planning_astarWrapper(const path_planning_astarWrapper&) = delete;
    path_planning_astarWrapper& operator=(const path_planning_astarWrapper&) = delete;
    
    // Allow move constructor and assignment
    path_planning_astarWrapper(path_planning_astarWrapper&& other) noexcept
        : node_(other.node_), stream_(other.stream_), device_id_(other.device_id_),
          initialized_(other.initialized_), allocated_size_(other.allocated_size_),
          input_sizes_(std::move(other.input_sizes_)), output_sizes_(std::move(other.output_sizes_)),
          last_error_(std::move(other.last_error_)), perf_stats_(other.perf_stats_),
          progress_callback_(std::move(other.progress_callback_)) {
        
        // Move device memory pointers
        d_occupancy_grid_ = other.d_occupancy_grid_;
        other.d_occupancy_grid_ = nullptr;
        d_grid_width_ = other.d_grid_width_;
        other.d_grid_width_ = nullptr;
        d_grid_height_ = other.d_grid_height_;
        other.d_grid_height_ = nullptr;
        d_start_x_ = other.d_start_x_;
        other.d_start_x_ = nullptr;
        d_start_y_ = other.d_start_y_;
        other.d_start_y_ = nullptr;
        d_goal_x_ = other.d_goal_x_;
        other.d_goal_x_ = nullptr;
        d_goal_y_ = other.d_goal_y_;
        other.d_goal_y_ = nullptr;
        d_path_x_ = other.d_path_x_;
        other.d_path_x_ = nullptr;
        d_path_y_ = other.d_path_y_;
        other.d_path_y_ = nullptr;
        d_path_length_ = other.d_path_length_;
        other.d_path_length_ = nullptr;
        
        other.initialized_ = false;
        other.allocated_size_ = 0;
    }
    
    path_planning_astarWrapper& operator=(path_planning_astarWrapper&& other) noexcept {
        if (this != &other) {
            freeDeviceMemory();
            
            node_ = other.node_;
            stream_ = other.stream_;
            device_id_ = other.device_id_;
            initialized_ = other.initialized_;
            allocated_size_ = other.allocated_size_;
            input_sizes_ = std::move(other.input_sizes_);
            output_sizes_ = std::move(other.output_sizes_);
            last_error_ = std::move(other.last_error_);
            perf_stats_ = other.perf_stats_;
            progress_callback_ = std::move(other.progress_callback_);
            
            // Move device memory pointers
            d_occupancy_grid_ = other.d_occupancy_grid_;
            other.d_occupancy_grid_ = nullptr;
            d_grid_width_ = other.d_grid_width_;
            other.d_grid_width_ = nullptr;
            d_grid_height_ = other.d_grid_height_;
            other.d_grid_height_ = nullptr;
            d_start_x_ = other.d_start_x_;
            other.d_start_x_ = nullptr;
            d_start_y_ = other.d_start_y_;
            other.d_start_y_ = nullptr;
            d_goal_x_ = other.d_goal_x_;
            other.d_goal_x_ = nullptr;
            d_goal_y_ = other.d_goal_y_;
            other.d_goal_y_ = nullptr;
            d_path_x_ = other.d_path_x_;
            other.d_path_x_ = nullptr;
            d_path_y_ = other.d_path_y_;
            other.d_path_y_ = nullptr;
            d_path_length_ = other.d_path_length_;
            other.d_path_length_ = nullptr;
            
            other.initialized_ = false;
            other.allocated_size_ = 0;
        }
        return *this;
    }
    
    /**
     * @brief Initialize the wrapper with CUDA device
     * 
     * @param device_id CUDA device ID to use
     * @return true if initialization was successful
     */
    bool initialize(int device_id = 0) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        device_id_ = device_id;
        
        // Set CUDA device
        if (!checkCudaError(cudaSetDevice(device_id_), "cudaSetDevice")) {
            return false;
        }
        
        // Get device properties
        cudaDeviceProp prop;
        if (!checkCudaError(cudaGetDeviceProperties(&prop, device_id_), "cudaGetDeviceProperties")) {
            return false;
        }
        
        if (node_) {
            RCLCPP_INFO(node_->get_logger(), 
                "Initialized path_planning_astarWrapper on device %d: %s", 
                device_id_, prop.name);
        }
        
        initialized_ = true;
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    /**
     * @brief Process data from ROS2 Float32MultiArray message
     * 
     * @param input_msg Input ROS2 message
     * @param output_msg Output ROS2 message (will be populated)
     * @return true if processing was successful
     */
    bool processMessage(
        const std_msgs::msg::Float32MultiArray::SharedPtr& input_msg,
        std_msgs::msg::Float32MultiArray::SharedPtr& output_msg
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Convert ROS2 message to vector
        std::vector<float> input_data(input_msg->data.begin(), input_msg->data.end());
        std::vector<float> output_data;
        
        // Process data
        if (!processData(input_data, output_data)) {
            return false;
        }
        
        // Convert back to ROS2 message
        output_msg = std::make_shared<std_msgs::msg::Float32MultiArray>();
        output_msg->data = output_data;
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process data from ROS2 Image message
     * 
     * @param input_msg Input ROS2 image message
     * @param output_msg Output ROS2 image message (will be populated)
     * @return true if processing was successful
     */
    bool processImage(
        const sensor_msgs::msg::Image::SharedPtr& input_msg,
        sensor_msgs::msg::Image::SharedPtr& output_msg
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Convert image data to float vector
        std::vector<float> input_data;
        size_t pixel_count = input_msg->width * input_msg->height;
        
        if (input_msg->encoding == "rgb8" || input_msg->encoding == "bgr8") {
            input_data.resize(pixel_count * 3);
            for (size_t i = 0; i < pixel_count * 3; ++i) {
                input_data[i] = static_cast<float>(input_msg->data[i]) / 255.0f;
            }
        } else if (input_msg->encoding == "mono8") {
            input_data.resize(pixel_count);
            for (size_t i = 0; i < pixel_count; ++i) {
                input_data[i] = static_cast<float>(input_msg->data[i]) / 255.0f;
            }
        } else {
            last_error_ = "Unsupported image encoding: " + input_msg->encoding;
            return false;
        }
        
        std::vector<float> output_data;
        if (!processData(input_data, output_data)) {
            return false;
        }
        
        // Convert back to image message
        output_msg = std::make_shared<sensor_msgs::msg::Image>(*input_msg);
        output_msg->data.resize(output_data.size());
        
        for (size_t i = 0; i < output_data.size(); ++i) {
            output_msg->data[i] = static_cast<uint8_t>(std::clamp(output_data[i] * 255.0f, 0.0f, 255.0f));
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process raw data vectors
     * 
     * @param input_data Input data vector
     * @param output_data Output data vector (will be populated)
     * @return true if processing was successful
     */
    bool processData(
        const std::vector<float>& input_data,
        std::vector<float>& output_data
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Allocate device memory if needed
        if (!allocateDeviceMemory(input_data.size(), input_data.size())) {
            return false;
        }
        
        // Copy data to device
        if (!copyToDevice(input_data)) {
            return false;
        }
        
        // Launch kernel
        if (!launchKernel(input_data.size())) {
            return false;
        }
        
        // Copy results back
        if (!copyFromDevice(output_data)) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Process data with custom parameters
     * 
     * @param input_data Input data vector
     * @param output_data Output data vector (will be populated)
     * @param parameters Custom kernel parameters
     * @return true if processing was successful
     */
    bool processDataWithParameters(
        const std::vector<float>& input_data,
        std::vector<float>& output_data,
        const int*& parameters
    ) {
        if (!initialized_) {
            last_error_ = "Wrapper not initialized";
            return false;
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Allocate device memory if needed
        if (!allocateDeviceMemory(input_data.size(), input_data.size())) {
            return false;
        }
        
        // Copy data to device
        if (!copyToDevice(input_data)) {
            return false;
        }
        
        // Launch kernel with parameters
        if (!launchKernelWithParameters(input_data.size(), parameters)) {
            return false;
        }
        
        // Copy results back
        if (!copyFromDevice(output_data)) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.total_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        perf_stats_.call_count++;
        
        return true;
    }
    
    /**
     * @brief Get the last error message
     * 
     * @return std::string Last error message or empty string if no error
     */
    const std::string& getLastError() const { return last_error_; }
    
    /**
     * @brief Check if the wrapper is properly initialized
     * 
     * @return true if initialized and ready to use
     */
    bool isInitialized() const { return initialized_; }
    
    /**
     * @brief Get performance statistics
     * 
     * @return std::map<std::string, double> Performance metrics
     */
    std::map<std::string, double> getPerformanceStats() const {
        std::map<std::string, double> stats;
        
        if (perf_stats_.call_count > 0) {
            stats["total_time_ms"] = perf_stats_.total_time.count() / 1000.0;
            stats["kernel_time_ms"] = perf_stats_.kernel_time.count() / 1000.0;
            stats["memory_time_ms"] = perf_stats_.memory_time.count() / 1000.0;
            stats["call_count"] = static_cast<double>(perf_stats_.call_count);
            stats["error_count"] = static_cast<double>(perf_stats_.error_count);
            stats["avg_time_per_call_ms"] = (perf_stats_.total_time.count() / 1000.0) / perf_stats_.call_count;
        }
        
        return stats;
    }
    
    /**
     * @brief Reset performance statistics
     */
    void resetPerformanceStats() {
        perf_stats_ = PerformanceStats{};
    }
    
    /**
     * @brief Set callback for progress updates
     * 
     * @param callback Function to call with progress updates (0.0 to 1.0)
     */
    void setProgressCallback(std::function<void(float)> callback) {
        progress_callback_ = callback;
    }

private:
    // ROS2 node for logging and parameters
    rclcpp::Node* node_;
    
    // CUDA resources
    cudaStream_t stream_;
    int device_id_;
    bool initialized_;
    
    // Device memory pointers
    float** d_occupancy_grid_ = nullptr;  //!< Device memory for occupancy_grid
    int* d_grid_width_ = nullptr;  //!< Device memory for grid_width
    int* d_grid_height_ = nullptr;  //!< Device memory for grid_height
    int* d_start_x_ = nullptr;  //!< Device memory for start_x
    int* d_start_y_ = nullptr;  //!< Device memory for start_y
    int* d_goal_x_ = nullptr;  //!< Device memory for goal_x
    int* d_goal_y_ = nullptr;  //!< Device memory for goal_y
    int** d_path_x_ = nullptr;  //!< Device memory for path_x
    int** d_path_y_ = nullptr;  //!< Device memory for path_y
    int** d_path_length_ = nullptr;  //!< Device memory for path_length
    
    // Memory management
    size_t allocated_size_ = 0;
    std::vector<size_t> input_sizes_;
    std::vector<size_t> output_sizes_;
    
    // Error handling
    std::string last_error_;
    
    // Performance tracking
    struct PerformanceStats {
        std::chrono::microseconds total_time{0};
        std::chrono::microseconds kernel_time{0};
        std::chrono::microseconds memory_time{0};
        size_t call_count = 0;
        size_t error_count = 0;
    } perf_stats_;
    
    // Progress callback
    std::function<void(float)> progress_callback_;
    
    // Internal methods
    bool checkCudaError(cudaError_t status, const std::string& context) {
        if (status != cudaSuccess) {
            last_error_ = context + ": " + cudaGetErrorString(status);
            perf_stats_.error_count++;
            
            if (node_) {
                RCLCPP_ERROR(node_->get_logger(), "%s", last_error_.c_str());
            }
            return false;
        }
        return true;
    }
    
    bool allocateDeviceMemory(size_t input_size, size_t output_size) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Free existing memory if sizes don't match
        if (allocated_size_ != input_size) {
            freeDeviceMemory();
        }
        
        if (allocated_size_ == 0) {
            cudaError_t status = cudaMalloc(&d_occupancy_grid_, input_size * sizeof(float*));
            if (!checkCudaError(status, "cudaMalloc for d_occupancy_grid_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_grid_width_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_grid_width_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_grid_height_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_grid_height_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_start_x_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_start_x_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_start_y_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_start_y_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_goal_x_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_goal_x_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_goal_y_, input_size * sizeof(int));
            if (!checkCudaError(status, "cudaMalloc for d_goal_y_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_path_x_, input_size * sizeof(int*));
            if (!checkCudaError(status, "cudaMalloc for d_path_x_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_path_y_, input_size * sizeof(int*));
            if (!checkCudaError(status, "cudaMalloc for d_path_y_")) {
                return false;
            }
            cudaError_t status = cudaMalloc(&d_path_length_, input_size * sizeof(int*));
            if (!checkCudaError(status, "cudaMalloc for d_path_length_")) {
                return false;
            }
            
            allocated_size_ = input_size;
            input_sizes_.push_back(input_size);
            output_sizes_.push_back(output_size);
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    void freeDeviceMemory() {
        if (d_occupancy_grid_) {
            cudaFree(d_occupancy_grid_);
            d_occupancy_grid_ = nullptr;
        }
        if (d_grid_width_) {
            cudaFree(d_grid_width_);
            d_grid_width_ = nullptr;
        }
        if (d_grid_height_) {
            cudaFree(d_grid_height_);
            d_grid_height_ = nullptr;
        }
        if (d_start_x_) {
            cudaFree(d_start_x_);
            d_start_x_ = nullptr;
        }
        if (d_start_y_) {
            cudaFree(d_start_y_);
            d_start_y_ = nullptr;
        }
        if (d_goal_x_) {
            cudaFree(d_goal_x_);
            d_goal_x_ = nullptr;
        }
        if (d_goal_y_) {
            cudaFree(d_goal_y_);
            d_goal_y_ = nullptr;
        }
        if (d_path_x_) {
            cudaFree(d_path_x_);
            d_path_x_ = nullptr;
        }
        if (d_path_y_) {
            cudaFree(d_path_y_);
            d_path_y_ = nullptr;
        }
        if (d_path_length_) {
            cudaFree(d_path_length_);
            d_path_length_ = nullptr;
        }
        
        allocated_size_ = 0;
        input_sizes_.clear();
        output_sizes_.clear();
    }
    
    bool copyToDevice(const std::vector<float>& input_data) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        cudaError_t status = cudaMemcpy(d_occupancy_grid_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_occupancy_grid_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_grid_width_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_grid_width_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_grid_height_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_grid_height_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_start_x_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_start_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_start_y_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_start_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_goal_x_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_goal_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_goal_y_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_goal_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_path_x_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_path_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_path_y_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_path_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(d_path_length_, input_data.data(), 
                                       input_data.size() * sizeof(float), cudaMemcpyHostToDevice);
        if (!checkCudaError(status, "cudaMemcpy H2D for d_path_length_")) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool copyFromDevice(std::vector<float>& output_data) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        output_data.resize(allocated_size_);
        
        cudaError_t status = cudaMemcpy(output_data.data(), d_occupancy_grid_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_occupancy_grid_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_grid_width_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_grid_width_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_grid_height_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_grid_height_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_start_x_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_start_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_start_y_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_start_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_goal_x_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_goal_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_goal_y_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_goal_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_path_x_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_path_x_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_path_y_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_path_y_")) {
            return false;
        }
        cudaError_t status = cudaMemcpy(output_data.data(), d_path_length_, 
                                       allocated_size_ * sizeof(float), cudaMemcpyDeviceToHost);
        if (!checkCudaError(status, "cudaMemcpy D2H for d_path_length_")) {
            return false;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.memory_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool launchKernel(size_t num_elements) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Calculate grid and block dimensions
        int block_size = 256;
        int grid_size = (num_elements + block_size - 1) / block_size;
        
        // Launch kernel
        path_planning_astar_kernel<<<grid_size, block_size, 4096, stream_>>>(
            d_occupancy_grid_,            d_grid_width_,            d_grid_height_,            d_start_x_,            d_start_y_,            d_goal_x_,            d_goal_y_,            d_path_x_,            d_path_y_,            d_path_length_            num_elements
        );
        
        // Check for kernel launch errors
        if (!checkCudaError(cudaGetLastError(), "Kernel launch")) {
            return false;
        }
        
        // Synchronize if no stream
        if (stream_ == nullptr) {
            if (!checkCudaError(cudaDeviceSynchronize(), "cudaDeviceSynchronize")) {
                return false;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.kernel_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
    
    bool launchKernelWithParameters(size_t num_elements, const int*& parameters) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // Calculate grid and block dimensions
        int block_size = 256;
        int grid_size = (num_elements + block_size - 1) / block_size;
        
        // Launch kernel with parameters
        path_planning_astar_kernel<<<grid_size, block_size, 4096, stream_>>>(
            d_occupancy_grid_,            d_grid_width_,            d_grid_height_,            d_start_x_,            d_start_y_,            d_goal_x_,            d_goal_y_,            d_path_x_,            d_path_y_,            d_path_length_            num_elements,
            parameters
        );
        
        // Check for kernel launch errors
        if (!checkCudaError(cudaGetLastError(), "Kernel launch with parameters")) {
            return false;
        }
        
        // Synchronize if no stream
        if (stream_ == nullptr) {
            if (!checkCudaError(cudaDeviceSynchronize(), "cudaDeviceSynchronize")) {
                return false;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        perf_stats_.kernel_time += std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        
        return true;
    }
};

// Factory function for creating wrapper instances
inline std::unique_ptr<path_planning_astarWrapper> createpath_planning_astarWrapper(
    rclcpp::Node* node = nullptr,
    cudaStream_t stream = nullptr) {
    return std::make_unique<path_planning_astarWrapper>(node, stream);
}

} // namespace robodsl

#endif // PATH_PLANNING_ASTAR_KERNEL_HPP
